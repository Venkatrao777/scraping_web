{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0211fe99-520f-480b-8d54-6eeca695253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 jobs\n",
      "001. None | None | None \n",
      "    /hiring/jobs/latest/export/?format=csv\n",
      "002. None | None | None \n",
      "    /hiring/jobs/latest/export/?format=json\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "BASE_URL = \"https://foorilla.com/hiring/\"\n",
    "\n",
    "async def scrape_all_jobs():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(BASE_URL)\n",
    "        await page.wait_for_selector('a[href*=\"/hiring/jobs/\"]')\n",
    "\n",
    "        # Infinite scroll until no new jobs load\n",
    "        last_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "        while True:\n",
    "            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            await asyncio.sleep(1.5)\n",
    "            new_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Extract job listings\n",
    "        jobs = []\n",
    "        links = await page.query_selector_all('a[href*=\"/hiring/jobs/\"]')\n",
    "        seen_urls = set()\n",
    "        for link in links:\n",
    "            url = await link.get_attribute(\"href\")\n",
    "            if not url or url in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(url)\n",
    "\n",
    "            title_el = await link.query_selector(\".title\")\n",
    "            company_el = await link.query_selector(\".company\")\n",
    "            location_el = await link.query_selector(\".region\")\n",
    "\n",
    "            jobs.append({\n",
    "                \"title\": (await title_el.inner_text()) if title_el else None,\n",
    "                \"company\": (await company_el.inner_text()) if company_el else None,\n",
    "                \"location\": (await location_el.inner_text()) if location_el else None,\n",
    "                \"url\": url\n",
    "            })\n",
    "\n",
    "        await browser.close()\n",
    "        return jobs\n",
    "\n",
    "nest_asyncio.apply()\n",
    "if __name__ == \"__main__\":\n",
    "    results = asyncio.get_event_loop().run_until_complete(scrape_all_jobs())\n",
    "    print(f\"Found {len(results)} jobs\")\n",
    "    for i, job in enumerate(results, 1):\n",
    "        print(f\"{i:03d}. {job['title']} | {job['company']} | {job['location']} \\n    {job['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce98d632-8fca-40f2-836b-764f06309747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': None, 'company': None, 'location': None, 'url': '/hiring/jobs/latest/export/?format=csv'}, {'title': None, 'company': None, 'location': None, 'url': '/hiring/jobs/latest/export/?format=json'}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c89eb3-159a-4737-8541-4153b7059448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 jobs\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  # needed in Codespaces/Jupyter interactive\n",
    "\n",
    "BASE_URL = \"https://foorilla.com/hiring/\"\n",
    "\n",
    "async def scrape_all_jobs():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(BASE_URL)\n",
    "        await page.wait_for_selector('a[href*=\"/hiring/jobs/\"]')\n",
    "\n",
    "        # Infinite scroll\n",
    "        last_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "        while True:\n",
    "            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            await asyncio.sleep(1.5)\n",
    "            new_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        jobs = []\n",
    "        seen_urls = set()\n",
    "\n",
    "        links = await page.query_selector_all('a[href*=\"/hiring/jobs/\"]')\n",
    "        for link in links:\n",
    "            url = await link.get_attribute(\"href\")\n",
    "\n",
    "            # Skip if export links or already seen\n",
    "            if not url or \"export\" in url or url in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(url)\n",
    "\n",
    "            title_el = await link.query_selector(\".title\")\n",
    "            company_el = await link.query_selector(\".company\")\n",
    "            location_el = await link.query_selector(\".region\")\n",
    "\n",
    "            # Skip if no title found (not a real job card)\n",
    "            if not title_el:\n",
    "                continue\n",
    "\n",
    "            jobs.append({\n",
    "                \"title\": (await title_el.inner_text()) if title_el else None,\n",
    "                \"company\": (await company_el.inner_text()) if company_el else None,\n",
    "                \"location\": (await location_el.inner_text()) if location_el else None,\n",
    "                \"url\": url\n",
    "            })\n",
    "\n",
    "        await browser.close()\n",
    "        return jobs\n",
    "\n",
    "\n",
    "# Run in Codespaces interactive\n",
    "results = asyncio.get_event_loop().run_until_complete(scrape_all_jobs())\n",
    "print(f\"Found {len(results)} jobs\")\n",
    "for i, job in enumerate(results, 1):\n",
    "    print(f\"{i:03d}. {job['title']} | {job['company']} | {job['location']} \\n    {job['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "187c0579-0b5a-49c8-930e-28a7917f1f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 jobs\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def scrape_hiring_jobs():\n",
    "    jobs = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)  # change to False for debug\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://foorilla.com/hiring\", wait_until=\"networkidle\")\n",
    "        \n",
    "        # Wait a bit for dynamic content to load\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        # Select all job cards\n",
    "        job_cards = await page.query_selector_all(\"ul#hiring a.col.py-2\")\n",
    "        \n",
    "        for card in job_cards:\n",
    "            title = await card.query_selector(\".title\")\n",
    "            company = await card.query_selector(\".company:not(.region)\")\n",
    "            location = await card.query_selector(\".region.company\")\n",
    "\n",
    "            jobs.append({\n",
    "                \"title\": await title.inner_text() if title else None,\n",
    "                \"company\": await company.inner_text() if company else None,\n",
    "                \"location\": await location.inner_text() if location else None,\n",
    "                \"url\": await card.get_attribute(\"href\")\n",
    "            })\n",
    "\n",
    "        await browser.close()\n",
    "    return jobs\n",
    "\n",
    "# Run the scraper\n",
    "async def main():\n",
    "    job_list = await scrape_hiring_jobs()\n",
    "    print(f\"Found {len(job_list)} jobs\")\n",
    "    for i, job in enumerate(job_list, 1):\n",
    "        print(f\"{i:03d}. {job['title']} | {job['company']} | {job['location']}\\n    {job['url']}\")\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f0afab-c353-405a-aa93-83915e2de777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html class=\"h-100 overflow-hidden\" lang=\"en\" data-bs-theme=\"dark\" style=\"--content-height: 670px;\"><head>\n",
      "<meta charset=\"utf-8\">\n",
      "<meta name=\"viewport\" content=\"width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1\">\n",
      "<title>all coding</title>\n",
      "<meta name=\"description\" content=\"The career platform for coders, builders, hackers and makers.\">\n",
      "<link rel=\"canonical\" href=\"https://foorilla.com/hiring/\">\n",
      "<link href=\"/s/css/style.min.css?v=0.9.17\" rel=\"stylesheet\">\n",
      "<link href=\"/s/admin/css/vendor/select2/select2.min.css?v=0.9.17\" rel=\"stylesheet\">\n",
      "<link href=\"/s/django_select2/django_select2.css?v=0.9.17\" rel=\"stylesheet\">\n",
      "<link rel=\"shortcut icon\" href=\"/s/img/favicon.ico\">\n",
      "<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/s/img/apple-icon-180x180.png\">\n",
      "<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/s/img/apple-icon-152x152.png\">\n",
      "<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/s/img/apple-icon-76x76.png\">\n",
      "<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/s/img/apple-icon-60x60.png\">\n",
      "<link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"/s/img/favicon-192x192.png\">\n",
      "<link rel=\"icon\" type=\"image/png\" sizes=\"96x96\" href=\"/s/img/favicon-96x96.png\">\n",
      "<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/s/img/favicon-32x32.png\">\n",
      "<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/s/img/favicon-16x16.png\">\n",
      "<meta property=\"og:type\" content=\"website\">\n",
      "<meta property=\"og:title\" content=\"foo🦍 ~/all coding\">\n",
      "<meta property=\"og:description\" content=\"T\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def inspect_hiring_page():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)  # Change to False if you can see UI\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://foorilla.com/hiring\", wait_until=\"networkidle\")\n",
    "        await page.wait_for_timeout(3000)  # wait for JS to load jobs\n",
    "        \n",
    "        html_content = await page.content()\n",
    "        print(html_content[:1500])  # preview start of DOM\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(inspect_hiring_page())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcae9503-5265-4f00-9181-9dceba025d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen genericpath>:89: RuntimeWarning: coroutine 'scrape_all_jobs' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Page.wait_for_selector: Timeout 30000ms exceeded.\nCall log:\n  - waiting for locator(\"ul#hiring\") to be visible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Saved job list HTML to hiring_jobs.html\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m browser.close()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43minspect_job_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/scraping_web/.web_venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36minspect_job_list\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.new_page()\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m page.goto(\u001b[33m\"\u001b[39m\u001b[33mhttps://foorilla.com/hiring\u001b[39m\u001b[33m\"\u001b[39m, wait_until=\u001b[33m\"\u001b[39m\u001b[33mnetworkidle\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m page.wait_for_selector(\u001b[33m\"\u001b[39m\u001b[33mul#hiring\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# wait until job list exists\u001b[39;00m\n\u001b[32m     13\u001b[39m html_content = \u001b[38;5;28;01mawait\u001b[39;00m page.inner_html(\u001b[33m\"\u001b[39m\u001b[33mul#hiring\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# only get job list HTML\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mhiring_jobs.html\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/scraping_web/.web_venv/lib/python3.12/site-packages/playwright/async_api/_generated.py:8181\u001b[39m, in \u001b[36mPage.wait_for_selector\u001b[39m\u001b[34m(self, selector, timeout, state, strict)\u001b[39m\n\u001b[32m   8110\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_for_selector\u001b[39m(\n\u001b[32m   8111\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   8112\u001b[39m     selector: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   8118\u001b[39m     strict: typing.Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   8119\u001b[39m ) -> typing.Optional[\u001b[33m\"\u001b[39m\u001b[33mElementHandle\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   8120\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Page.wait_for_selector\u001b[39;00m\n\u001b[32m   8121\u001b[39m \n\u001b[32m   8122\u001b[39m \u001b[33;03m    Returns when element specified by selector satisfies `state` option. Returns `null` if waiting for `hidden` or\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   8177\u001b[39m \u001b[33;03m    Union[ElementHandle, None]\u001b[39;00m\n\u001b[32m   8178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   8180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping.from_impl_nullable(\n\u001b[32m-> \u001b[39m\u001b[32m8181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._impl_obj.wait_for_selector(\n\u001b[32m   8182\u001b[39m             selector=selector, timeout=timeout, state=state, strict=strict\n\u001b[32m   8183\u001b[39m         )\n\u001b[32m   8184\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/scraping_web/.web_venv/lib/python3.12/site-packages/playwright/_impl/_page.py:423\u001b[39m, in \u001b[36mPage.wait_for_selector\u001b[39m\u001b[34m(self, selector, timeout, state, strict)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_for_selector\u001b[39m(\n\u001b[32m    417\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    418\u001b[39m     selector: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m     strict: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    422\u001b[39m ) -> Optional[ElementHandle]:\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._main_frame.wait_for_selector(**locals_to_params(\u001b[38;5;28mlocals\u001b[39m()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/scraping_web/.web_venv/lib/python3.12/site-packages/playwright/_impl/_frame.py:369\u001b[39m, in \u001b[36mFrame.wait_for_selector\u001b[39m\u001b[34m(self, selector, strict, timeout, state)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_for_selector\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    363\u001b[39m     selector: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     state: Literal[\u001b[33m\"\u001b[39m\u001b[33mattached\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdetached\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhidden\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvisible\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    367\u001b[39m ) -> Optional[ElementHandle]:\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m from_nullable_channel(\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._channel.send(\n\u001b[32m    370\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwaitForSelector\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._timeout, locals_to_params(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[32m    371\u001b[39m         )\n\u001b[32m    372\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/scraping_web/.web_venv/lib/python3.12/site-packages/playwright/_impl/_connection.py:69\u001b[39m, in \u001b[36mChannel.send\u001b[39m\u001b[34m(self, method, timeout_calculator, params, is_internal, title)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend\u001b[39m(\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     63\u001b[39m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     title: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     68\u001b[39m ) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.wrap_api_call(\n\u001b[32m     70\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m._inner_send(method, timeout_calculator, params, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     71\u001b[39m         is_internal,\n\u001b[32m     72\u001b[39m         title,\n\u001b[32m     73\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/scraping_web/.web_venv/lib/python3.12/site-packages/playwright/_impl/_connection.py:558\u001b[39m, in \u001b[36mConnection.wrap_api_call\u001b[39m\u001b[34m(self, cb, is_internal, title)\u001b[39m\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cb()\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m rewrite_error(error, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_st[\u001b[33m'\u001b[39m\u001b[33mapiName\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    560\u001b[39m     \u001b[38;5;28mself\u001b[39m._api_zone.set(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTimeoutError\u001b[39m: Page.wait_for_selector: Timeout 30000ms exceeded.\nCall log:\n  - waiting for locator(\"ul#hiring\") to be visible\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def inspect_job_list():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)  # set to False if you want UI\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://foorilla.com/hiring\", wait_until=\"networkidle\")\n",
    "        await page.wait_for_selector(\"ul#hiring\")  # wait until job list exists\n",
    "        html_content = await page.inner_html(\"ul#hiring\")  # only get job list HTML\n",
    "        with open(\"hiring_jobs.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_content)\n",
    "        print(\"✅ Saved job list HTML to hiring_jobs.html\")\n",
    "        await browser.close()\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(inspect_job_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58964c6-4b38-4ba7-951c-fc9bf5de56f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved full page HTML to full_body.html\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def dump_full_body():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://foorilla.com/hiring\", wait_until=\"networkidle\")\n",
    "        await page.wait_for_timeout(5000)  # wait for JS to run\n",
    "        \n",
    "        html_content = await page.content()\n",
    "        with open(\"full_body.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        print(\"✅ Saved full page HTML to full_body.html\")\n",
    "        await browser.close()\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(dump_full_body())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f6f4a7-c65e-4c1c-838c-fa84ea4501b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 jobs\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def scrape_hiring_jobs():\n",
    "    jobs = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://foorilla.com/hiring\", wait_until=\"networkidle\")\n",
    "        await page.wait_for_timeout(3000)  # let jobs load\n",
    "\n",
    "        job_cards = await page.query_selector_all(\"a.col.py-2\")\n",
    "        \n",
    "        for card in job_cards:\n",
    "            title = await card.query_selector(\".title\")\n",
    "            company = await card.query_selector(\".company:not(.region)\")\n",
    "            location = await card.query_selector(\".region.company\")\n",
    "\n",
    "            jobs.append({\n",
    "                \"title\": await title.inner_text() if title else None,\n",
    "                \"company\": await company.inner_text() if company else None,\n",
    "                \"location\": await location.inner_text() if location else None,\n",
    "                \"url\": await card.get_attribute(\"href\")\n",
    "            })\n",
    "\n",
    "        await browser.close()\n",
    "    return jobs\n",
    "\n",
    "async def main():\n",
    "    job_list = await scrape_hiring_jobs()\n",
    "    print(f\"Found {len(job_list)} jobs\")\n",
    "    for i, job in enumerate(job_list, 1):\n",
    "        print(f\"{i:03d}. {job['title']} | {job['company']} | {job['location']}\\n    {job['url']}\")\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4531dc20-4592-42ba-9dc3-1e7ce0c49511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 jobs\n",
      "001. Software Development Engineer 2-6 | India - Bangalore - Remote Office [R] | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/software-development-engineer-2-6-india-bangalore-remote-office-819036/\n",
      "002. IT Infrastructure Engineer | Hong Kong | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/it-infrastructure-engineer-hong-kong-819211/\n",
      "003. Senior Software Engineer | INBLR02 - Bangalore - Milesstone Buildcon, … | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-software-engineer-inblr02-bangalore-milesstone-buildcon-india-819781/\n",
      "004. Software System Engineer | Shenyang - PIC, China | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/software-system-engineer-shenyang-pic-china-819978/\n",
      "005. Junior Automation Tester | RO - BUCHAREST BULEVARDUL ION MIHALACHE … | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/junior-automation-tester-ro-bucharest-bulevardul-ion-mihalache-15-17-romania-820019/\n",
      "006. Staff Facilities Engineer (Electrical) | Singapore - Woodlands - NorthTech | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-facilities-engineer-electrical-singapore-woodlands-northtech-820187/\n",
      "007. Java Fullstack Developer - 2-4 Years | PLOT NO-1, S.NO. 77, India | 3h ago\n",
      "    https://foorilla.com/hiring/jobs/java-fullstack-developer-2-4-years-plot-no-1-sno-77-india-818965/\n",
      "008. Senior Technical Support Engineer (Integration) | Tokyo, Japan | 4h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-technical-support-engineer-integration-tokyo-japan-819907/\n",
      "009. Teamcenter Systems Administrator (Onsite) | Houston, TX, United States | 4h ago\n",
      "    https://foorilla.com/hiring/jobs/teamcenter-systems-administrator-onsite-houston-tx-united-states-820021/\n",
      "010. Database Engineer- Sr. Consultant level- NoSQL | Highlands Ranch, CO, United States | 4h ago\n",
      "    https://foorilla.com/hiring/jobs/database-engineer-sr-consultant-level-nosql-highlands-ranch-co-united-states-819714/\n",
      "011. Software Engineer OOP (Hybrid) | Ciudad de México, DIF, Mexico | 4h ago\n",
      "    https://foorilla.com/hiring/jobs/software-engineer-oop-hybrid-ciudad-de-mexico-dif-mexico-819782/\n",
      "012. Senior Solution Engineer, Insurance | Lehi, UT, United States | 4h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-solution-engineer-insurance-lehi-ut-united-states-820215/\n",
      "013. Service Now Developer | Medellín, Antioquia, Colombia | 4h ago\n",
      "    https://foorilla.com/hiring/jobs/service-now-developer-medellin-antioquia-colombia-820203/\n",
      "014. Cloud Infrastructure Engineer - Hybrid Tempe | Tempe, AZ, United States | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/cloud-infrastructure-engineer-hybrid-tempe-tempe-az-united-states-819662/\n",
      "015. Cybersecurity Engineer, M&A Automation | Austin, TX, United States | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/cybersecurity-engineer-ma-automation-austin-tx-united-states-819668/\n",
      "016. Senior Data Scientist | Herndon, VA, United States | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-data-scientist-herndon-va-united-states-819701/\n",
      "017. Staff Software Engineer | Santa Clara, CA, United States | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-software-engineer-santa-clara-ca-united-states-819783/\n",
      "018. Software Engineer | Overland Park, KS, United States | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/software-engineer-overland-park-ks-united-states-819784/\n",
      "019. Consultant- Data Analyst | New York, NY, United States | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/consultant-data-analyst-new-york-ny-united-states-819675/\n",
      "020. Senior Data Engineer II | New York, NY, United States [R] | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-data-engineer-ii-new-york-ny-united-states-819690/\n",
      "021. Senior Software Engineer II , Retail Pricing | New York, NY, United States [R] | 5h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-software-engineer-ii-retail-pricing-new-york-ny-united-states-819785/\n",
      "022. Senior Software Engineer II, Commercial & Wealth | New York, NY, United States [R] | 6h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-software-engineer-ii-commercial-wealth-new-york-ny-united-states-819786/\n",
      "023. Staff Full-Stack Software Engineer, Dev Agent Tools | Santa Clara, California, United States | 6h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-full-stack-software-engineer-dev-agent-tools-santa-clara-california-united-states-819737/\n",
      "024. Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience | Seattle, WA, United States | 6h ago\n",
      "    https://foorilla.com/hiring/jobs/business-analyst-ii-data-compliance-analyst-ii-legacy-is-operational-experience-seattle-wa-united-states-819979/\n",
      "025. Staff Software Engineer, Lending | Reading, UNITED KINGDOM, United Kingdom [R] | 6h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-software-engineer-lending-reading-united-kingdom-united-kingdom-819787/\n",
      "026. Staff Software Engineer, Tokenization | Austin, TX, United States [R] | 6h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-software-engineer-tokenization-austin-tx-united-states-819788/\n",
      "027. Senior Staff Test Engineer / Team Leader | Austin, TEXAS, United States | 6h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-staff-test-engineer-team-leader-austin-texas-united-states-820022/\n",
      "028. AI Research Engineer- Advanced Driving Assistance Systems (ADAS) | Sunnyvale, CA, United States | 7h ago\n",
      "    https://foorilla.com/hiring/jobs/ai-research-engineer-advanced-driving-assistance-systems-adas-sunnyvale-ca-united-states-819637/\n",
      "029. Associate Solutions Designer | Highlands Ranch, CO, United States | 7h ago\n",
      "    https://foorilla.com/hiring/jobs/associate-solutions-designer-highlands-ranch-co-united-states-819929/\n",
      "030. Principal Engineer Software (Prisma Access) - NetSec | Pune, MH, India | 7h ago\n",
      "    https://foorilla.com/hiring/jobs/principal-engineer-software-prisma-access-netsec-pune-mh-india-819748/\n",
      "031. Backend Engineer | Montevideo, URUGUAY, Uruguay | 7h ago\n",
      "    https://foorilla.com/hiring/jobs/backend-engineer-montevideo-uruguay-uruguay-819655/\n",
      "032. Staff Engineer Software (Prisma Access)- NetSec | Pune, MH, India | 7h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-engineer-software-prisma-access-netsec-pune-mh-india-819749/\n",
      "033. Solutions Consultant 2 - FSI | Reston, VA, United States | 7h ago\n",
      "    https://foorilla.com/hiring/jobs/solutions-consultant-2-fsi-reston-va-united-states-819930/\n",
      "034. Cybersecurity Engineer - GRC | Austin, TX, United States | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/cybersecurity-engineer-grc-austin-tx-united-states-819669/\n",
      "035. Senior Staff Software Engineer (Cloud NW & AI Security) | Santa Clara, CA, United States | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-staff-software-engineer-cloud-nw-ai-security-santa-clara-ca-united-states-819789/\n",
      "036. Desarrollador Backend Java Semisenior | Bogotá, Bogota, Colombia | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/desarrollador-backend-java-semisenior-bogota-bogota-colombia-819739/\n",
      "037. Technical Enablement Specialist - NetSec | Plano, TX, United States | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/technical-enablement-specialist-netsec-plano-tx-united-states-819750/\n",
      "038. Senior Identity Security Services Engineer | Chicago, US-IL, United States | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-identity-security-services-engineer-chicago-us-il-united-states-820023/\n",
      "039. Data Insights Engineer | Foster City, CA, United States | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/data-insights-engineer-foster-city-ca-united-states-820024/\n",
      "040. Industrial Engineer | Greensboro, NC, United States | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/industrial-engineer-greensboro-nc-united-states-820261/\n",
      "041. Creative Graphic Engineer - AI & Design | Pune, MH, India | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/creative-graphic-engineer-ai-design-pune-mh-india-820188/\n",
      "042. Conversational AI Developer (Google CCAI / AWS) | All cities, India | 8h ago\n",
      "    https://foorilla.com/hiring/jobs/conversational-ai-developer-google-ccai-aws-all-cities-india-819635/\n",
      "043. Senior Software Engineer | Hyderabad, India | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-software-engineer-hyderabad-india-819790/\n",
      "044. Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance | Foster City, CA, United States | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/cyber-security-engineer-sr-consultant-level-regulatory-audit-compliance-foster-city-ca-united-states-819663/\n",
      "045. Engineer, Software Development Engineering (Apps) | Bengaluru, KA, India | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/engineer-software-development-engineering-apps-bengaluru-ka-india-819771/\n",
      "046. MID Software Engineer / Fullstack | Bogota, DC, Colombia | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/mid-software-engineer-fullstack-bogota-dc-colombia-819727/\n",
      "047. Data Governance Specialist | São Paulo, SP, Brazil | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/data-governance-specialist-sao-paulo-sp-brazil-820025/\n",
      "048. Data Governance Specialist | Buenos Aires, Buenos Aires, Argentina | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/data-governance-specialist-buenos-aires-buenos-aires-argentina-820026/\n",
      "049. Sr Dir PM, Data & Analytics | Santa Clara, CALIFORNIA, United States | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/sr-dir-pm-data-analytics-santa-clara-california-united-states-819639/\n",
      "050. Senior Technical Marketing Engineer (SASE) | Santa Clara, CA, United States | 9h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-technical-marketing-engineer-sase-santa-clara-ca-united-states-819931/\n",
      "051. Sr Software Engineer Backend | Buenos Aires, Argentina | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/sr-software-engineer-backend-buenos-aires-argentina-819791/\n",
      "052. C++ Software Engineer - Trading applications | New York, NY, United States | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/c-software-engineer-trading-applications-new-york-ny-united-states-819792/\n",
      "053. Senior C++ Developer | Córdoba, Córdoba Province, Argentina | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-c-developer-cordoba-cordoba-province-argentina-819980/\n",
      "054. Staff Software Engineer | London, United Kingdom | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-software-engineer-london-united-kingdom-819793/\n",
      "055. Scientific Data Analyst | Vaughan, ON, Canada | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/scientific-data-analyst-vaughan-on-canada-819676/\n",
      "056. Sr Production Service Engineer - Cloud Operations - Federal | Orlando, Florida, United States | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/sr-production-service-engineer-cloud-operations-federal-orlando-florida-united-states-819932/\n",
      "057. Network Systems Engineer (Pre-Sales) | Detroit, MI, United States | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/network-systems-engineer-pre-sales-detroit-mi-united-states-820262/\n",
      "058. Senior Solutions Engineer, PAM | Boston, US-MA, United States | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-solutions-engineer-pam-boston-us-ma-united-states-819902/\n",
      "059. Principal Software Engineer (Intrusion Prevention System Development) | Santa Clara, CA, United States | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/principal-software-engineer-intrusion-prevention-system-development-santa-clara-ca-united-states-819794/\n",
      "060. Senior Engineering Manager – Data Science (Pricing & Fleet Optimization) (m/f/d) | Lisbon, Portugal | 10h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-engineering-manager-data-science-pricing-fleet-optimization-mfd-lisbon-portugal-819702/\n",
      "061. Ops Test Analyst - China Lake CA | Ridgecrest, CA, United States | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/ops-test-analyst-china-lake-ca-ridgecrest-ca-united-states-819212/\n",
      "062. Senior Data Engineer | Philadelphia, PA, United States | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-data-engineer-philadelphia-pa-united-states-819692/\n",
      "063. Backup and Recovery Administrator | Huntington, WV, United States | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/backup-and-recovery-administrator-huntington-wv-united-states-818641/\n",
      "064. Senior Genesys Cloud CX Consultant | All cities, India [R] | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-genesys-cloud-cx-consultant-all-cities-india-819933/\n",
      "065. Product Marketing Manager | Staines, england, United Kingdom | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/product-marketing-manager-staines-england-united-kingdom-818642/\n",
      "066. Associate Software Engineer | Bristol, United Kingdom | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/associate-software-engineer-bristol-united-kingdom-818578/\n",
      "067. Associate Flood Modeller / Hydrologist | Brisbane, QLD, AU | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/associate-flood-modeller-hydrologist-brisbane-qld-au-818813/\n",
      "068. Senior Manager, Retail Analytics | Pittsburgh, PA, United States | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-manager-retail-analytics-pittsburgh-pa-united-states-818450/\n",
      "069. Cyber Threat Analyst 1 | Fairfax, VA, United States | 11h ago\n",
      "    https://foorilla.com/hiring/jobs/cyber-threat-analyst-1-fairfax-va-united-states-818643/\n",
      "070. Développeur Fullstack PHP Symfony / React senior H/F | Valbonne, Provence-Alpes-Côte d'Azur, France | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/developpeur-fullstack-php-symfony-react-senior-hf-valbonne-provence-alpes-cote-dazur-france-819728/\n",
      "071. Engineer II, Golang - (Logistics, Deliveries) | Berlin, Germany | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/engineer-ii-golang-logistics-deliveries-berlin-germany-819738/\n",
      "072. Senior BI Engineer | Hybrid (08005, Barcelona, Barcelona, Spain) | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-bi-engineer-hybrid-08005-barcelona-barcelona-spain-818474/\n",
      "073. Software Engineer-Python | DevOps | Cloud | All cities, India | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/software-engineer-python-devops-cloud-all-cities-india-819718/\n",
      "074. Director, Data Science, Visa Consulting & Analytics, India and South Asia | Mumbai, INDIA, India | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/director-data-science-visa-consulting-analytics-india-and-south-asia-mumbai-india-india-819640/\n",
      "075. Staff Product Security Engineer | Petah Tikva, Israel | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/staff-product-security-engineer-petah-tikva-israel-819769/\n",
      "076. Senior Data Engineer (Pipelines & Ingestion) (f/m/d) - Metrify Smart Metering | Berlin, BE, Germany | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-data-engineer-pipelines-ingestion-fmd-metrify-smart-metering-berlin-be-germany-819693/\n",
      "077. Algorithm Engineer | Tel Aviv-Yafo, Tel Aviv District, IL | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/algorithm-engineer-tel-aviv-yafo-tel-aviv-district-il-818400/\n",
      "078. Senior Data Engineer | Buenos Aires, Buenos Aires, Argentina | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-data-engineer-buenos-aires-buenos-aires-argentina-819694/\n",
      "079. Software Engineer IV | Annapolis Junction, MD | 12h ago\n",
      "    https://foorilla.com/hiring/jobs/software-engineer-iv-annapolis-junction-md-818579/\n",
      "080. Software Engineer III | Annapolis Junction, MD | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/software-engineer-iii-annapolis-junction-md-818580/\n",
      "081. AI Engineer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/ai-engineer-tel-aviv-yafo-tel-aviv-district-il-818378/\n",
      "082. Alternance – Data analyst F/H | Ile-de-France, Yvelines (78) | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/alternance-data-analyst-fh-ile-de-france-yvelines-78-818861/\n",
      "083. Associate AI Engineer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/associate-ai-engineer-tel-aviv-yafo-tel-aviv-district-il-818379/\n",
      "084. Enterprise Account Executive, IL | Tel Aviv-Jaffa, Tel Aviv District, IL | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/enterprise-account-executive-il-tel-aviv-jaffa-tel-aviv-district-il-818330/\n",
      "085. Chef de projet MOE H/F | France, Ile-de-France, Seine Saint-Denis (93) | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/chef-de-projet-moe-hf-france-ile-de-france-seine-saint-denis-93-819440/\n",
      "086. Website Content Manager | Kyiv, Kyiv, UA [R] | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/website-content-manager-kyiv-kyiv-ua-818338/\n",
      "087. Backend Engineer Golang (f|m|d) (100%) - Sophia-Antipolis - Hybrid or Remote working model | Valbonne, France [R] | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/backend-engineer-golang-fmd-100-sophia-antipolis-hybrid-or-remote-working-model-valbonne-france-819656/\n",
      "088. Web Designer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/web-designer-tel-aviv-yafo-tel-aviv-district-il-818645/\n",
      "089. IT Infrastructure Director | Herzliya, Tel-Aviv district, IL | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/it-infrastructure-director-herzliya-tel-aviv-district-il-818616/\n",
      "090. Site Reliability Developer 4 | India | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/site-reliability-developer-4-india-818093/\n",
      "091. Technical Product Manager | Ramat Gan, Israel, IL | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/technical-product-manager-ramat-gan-israel-il-818646/\n",
      "092. Senior Data Scientist | Dublin, County Dublin, Ireland | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-data-scientist-dublin-county-dublin-ireland-819703/\n",
      "093. Mitarbeiter:in Data Science & Customer Support Freiburg im Breisgau oder Aachen, Deutschland | Freiburg im Breisgau, Germany | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/mitarbeiterin-data-science-customer-support-freiburg-im-breisgau-oder-aachen-deutschland-freiburg-im-breisgau-germany-818002/\n",
      "094. Product Owner DATA | Rabat, Morocco | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/product-owner-data-rabat-morocco-819934/\n",
      "095. Software Engineer with PHP, Symfony Framework & DB experience | Mumbai, MH, India | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/software-engineer-with-php-symfony-framework-db-experience-mumbai-mh-india-819795/\n",
      "096. Site Reliability Engineer | Athens, Athens, GR | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/site-reliability-engineer-athens-athens-gr-818566/\n",
      "097. Senior Software Architect | San Sebastian, Gipuzkoa, ES | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/senior-software-architect-san-sebastian-gipuzkoa-es-818647/\n",
      "098. Data & Reporting System(s) Coordinator | Hoffman Estates, IL, United States | 13h ago\n",
      "    https://foorilla.com/hiring/jobs/data-reporting-systems-coordinator-hoffman-estates-il-united-states-818648/\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from urllib.parse import urljoin\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "BASE = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "\n",
    "async def scrape_all_jobs():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(START, wait_until=\"networkidle\")\n",
    "\n",
    "        # Wait for the jobs column container\n",
    "        await page.wait_for_selector(\"#mc_1\")\n",
    "\n",
    "        # Infinite-scroll the jobs list container (not the window)\n",
    "        last_count = -1\n",
    "        while True:\n",
    "            # Count current jobs\n",
    "            count = await page.locator(\"#mc_1 li.list-group-item a.stretched-link\").count()\n",
    "            if count == last_count:\n",
    "                # No new items; stop\n",
    "                break\n",
    "            last_count = count\n",
    "\n",
    "            # Scroll the #mc_1 column to the bottom to trigger htmx \"intersect once\"\n",
    "            await page.evaluate(\"\"\"\n",
    "                () => {\n",
    "                  const el = document.querySelector('#mc_1');\n",
    "                  if (el) el.scrollTo(0, el.scrollHeight);\n",
    "                }\n",
    "            \"\"\")\n",
    "            await page.wait_for_timeout(1200)  # give htmx time to fetch & render\n",
    "\n",
    "        # Select all job rows\n",
    "        rows = page.locator(\"#mc_1 li.list-group-item\")\n",
    "        n = await rows.count()\n",
    "        jobs = []\n",
    "\n",
    "        for i in range(n):\n",
    "            row = rows.nth(i)\n",
    "            link = row.locator(\"a.stretched-link\")\n",
    "            if await link.count() == 0:\n",
    "                continue\n",
    "\n",
    "            title = (await link.inner_text()).strip()\n",
    "\n",
    "            # URL is in hx-get (href is empty)\n",
    "            hx_get = await link.get_attribute(\"hx-get\")\n",
    "            url = urljoin(BASE, hx_get) if hx_get else None\n",
    "\n",
    "            # time-ago (right side small in the first hstack)\n",
    "            time_ago = None\n",
    "            time_small = row.locator(\".hstack .flex-shrink-0.text-body-secondary small\").first\n",
    "            if await time_small.count():\n",
    "                time_ago = (await time_small.inner_text()).strip()\n",
    "\n",
    "            # location (right side .text-end small in the second hstack)\n",
    "            location = None\n",
    "            loc_small = row.locator(\".hstack .text-end small\").first\n",
    "            if await loc_small.count():\n",
    "                location = (await loc_small.inner_text()).strip()\n",
    "\n",
    "            jobs.append({\n",
    "                \"title\": title or None,\n",
    "                \"location\": location or None,\n",
    "                \"time_ago\": time_ago or None,\n",
    "                \"url\": url\n",
    "            })\n",
    "\n",
    "        await browser.close()\n",
    "        return jobs\n",
    "\n",
    "# Run in Codespaces/Jupyter\n",
    "results = asyncio.get_event_loop().run_until_complete(scrape_all_jobs())\n",
    "print(f\"Found {len(results)} jobs\")\n",
    "for i, job in enumerate(results, 1):\n",
    "    print(f\"{i:03d}. {job['title']} | {job['location']} | {job['time_ago']}\\n    {job['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c30440ba-70a9-4962-90b8-2bc570edc0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 0 jobs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from urllib.parse import urljoin, urlencode\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://foorilla.com\"\n",
    "LIST_PATH = \"/hiring/jobs/\"  # HTMX list endpoint used by the site\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def fetch_html(url, params=None, sleep=0.4):\n",
    "    \"\"\"GET a URL and return BeautifulSoup.\"\"\"\n",
    "    if params:\n",
    "        url = f\"{url}?{urlencode(params)}\"\n",
    "    r = requests.get(url, headers=HEADERS, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    time.sleep(sleep)  # be polite; avoid hammering\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_list_items(soup):\n",
    "    \"\"\"Parse one listing chunk (HTML returned by /hiring/jobs/?page=N).\"\"\"\n",
    "    jobs = []\n",
    "    # Each job row looks like: <li class=\"list-group-item\"> ... <a class=\"stretched-link\" hx-get=\"/hiring/jobs/<slug>/\">Title</a> ...\n",
    "    rows = soup.select(\"li.list-group-item\")\n",
    "    for row in rows:\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a:\n",
    "            continue\n",
    "        title = a.get_text(strip=True)\n",
    "        hx_get = a.get(\"hx-get\")  # detail endpoint\n",
    "        url = urljoin(BASE, hx_get) if hx_get else None\n",
    "\n",
    "        # time-ago (first hstack right side)\n",
    "        time_ago_el = row.select_one(\".hstack .flex-shrink-0.text-body-secondary small\")\n",
    "        time_ago = time_ago_el.get_text(strip=True) if time_ago_el else None\n",
    "\n",
    "        # location (second hstack right side)\n",
    "        location_el = row.select_one(\".hstack .text-end small\")\n",
    "        location = location_el.get_text(strip=True) if location_el else None\n",
    "\n",
    "        # optional: salary badge lives alongside tags; we can sniff it\n",
    "        # typically has class 'text-success-emphasis'\n",
    "        salary_el = row.select_one(\".text-success-emphasis\")\n",
    "        salary = salary_el.get_text(strip=True) if salary_el else None\n",
    "\n",
    "        jobs.append({\n",
    "            \"title\": title or None,\n",
    "            \"url\": url,\n",
    "            \"location\": location or None,\n",
    "            \"time_ago\": time_ago or None,\n",
    "            \"salary\": salary or None,\n",
    "        })\n",
    "    return jobs\n",
    "\n",
    "def find_next_page(soup):\n",
    "    \"\"\"\n",
    "    Pagination is exposed as a sentinel <li> that contains:\n",
    "    hx-get=\"/hiring/jobs/?page=N\"\n",
    "    We grab the max N we see (usually one).\n",
    "    \"\"\"\n",
    "    li = soup.select_one('li.list-group-item[hx-get*=\"?page=\"]')\n",
    "    if not li:\n",
    "        return None\n",
    "    hx = li.get(\"hx-get\")\n",
    "    # hx looks like /hiring/jobs/?page=2\n",
    "    m = re.search(r\"[?&]page=(\\d+)\", hx or \"\")\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def fetch_job_detail(detail_url):\n",
    "    \"\"\"Fetch job detail panel HTML (optional).\"\"\"\n",
    "    s = fetch_html(detail_url)\n",
    "    # Example: extract main header and description text\n",
    "    # The detail panel markup can vary; adjust selectors as needed\n",
    "    # Try a few best-effort selectors:\n",
    "    title = s.select_one(\"h1, h2, .h3, .job-title\")\n",
    "    desc = s.select_one(\"article, .content, .prose, .job-description, .markdown\")\n",
    "    apply_link = s.select_one('a[href*=\"apply\"], a[href*=\"careers\"], a[target=\"_blank\"]')\n",
    "    return {\n",
    "        \"detail_title\": title.get_text(strip=True) if title else None,\n",
    "        \"detail_snippet\": (desc.get_text(\" \", strip=True)[:500] + \"…\") if desc else None,\n",
    "        \"apply_link\": apply_link.get(\"href\") if apply_link else None,\n",
    "    }\n",
    "\n",
    "def scrape_all_jobs(include_details=False, max_pages=None):\n",
    "    \"\"\"\n",
    "    Crawl /hiring/jobs/ page by page via HTMX endpoints.\n",
    "    If include_details=True, fetch each job detail panel too.\n",
    "    \"\"\"\n",
    "    page = 1\n",
    "    all_jobs = []\n",
    "\n",
    "    while True:\n",
    "        soup = fetch_html(urljoin(BASE, LIST_PATH), params=None if page == 1 else {\"page\": page})\n",
    "        # On first call (/hiring/jobs/) we get page 1; for subsequent pages, use ?page=N\n",
    "\n",
    "        chunk_jobs = parse_list_items(soup)\n",
    "        if not chunk_jobs:\n",
    "            break\n",
    "        all_jobs.extend(chunk_jobs)\n",
    "\n",
    "        if include_details:\n",
    "            for job in chunk_jobs:\n",
    "                if job[\"url\"]:\n",
    "                    try:\n",
    "                        detail = fetch_job_detail(job[\"url\"])\n",
    "                        job.update(detail)\n",
    "                    except Exception as e:\n",
    "                        # non-fatal; keep going\n",
    "                        job[\"detail_error\"] = str(e)\n",
    "\n",
    "        if max_pages and page >= max_pages:\n",
    "            break\n",
    "\n",
    "        next_p = find_next_page(soup)\n",
    "        if not next_p or next_p == page:\n",
    "            break\n",
    "        page = next_p\n",
    "\n",
    "    return all_jobs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jobs = scrape_all_jobs(include_details=False)  # set True to fetch detail panel too\n",
    "    print(f\"Collected {len(jobs)} jobs\")\n",
    "    for i, j in enumerate(jobs, 1):\n",
    "        print(f\"{i:03d}. {j['title']} | {j.get('location') or '—'} | {j.get('time_ago') or '—'} | {j.get('salary') or '—'}\")\n",
    "        print(f\"     {j['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d83512a7-6003-42e3-8742-91724c3cddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 100 jobs\n",
      "001. Software Development Engineer 2-6 | India - Bangalore - Remote Office[R] | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-development-engineer-2-6-india-bangalore-remote-office-819036/\n",
      "002. IT Infrastructure Engineer | Hong Kong | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/it-infrastructure-engineer-hong-kong-819211/\n",
      "003. Senior Software Engineer | INBLR02 - Bangalore - Milesstone Buildcon, … | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-software-engineer-inblr02-bangalore-milesstone-buildcon-india-819781/\n",
      "004. Software System Engineer | Shenyang - PIC, China | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-system-engineer-shenyang-pic-china-819978/\n",
      "005. Junior Automation Tester | RO - BUCHAREST BULEVARDUL ION MIHALACHE … | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/junior-automation-tester-ro-bucharest-bulevardul-ion-mihalache-15-17-romania-820019/\n",
      "006. Staff Facilities Engineer (Electrical) | Singapore - Woodlands - NorthTech | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/staff-facilities-engineer-electrical-singapore-woodlands-northtech-820187/\n",
      "007. Java Fullstack Developer - 2-4 Years | PLOT NO-1, S.NO. 77, India | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/java-fullstack-developer-2-4-years-plot-no-1-sno-77-india-818965/\n",
      "008. Senior Technical Support Engineer (Integration) | Tokyo, Japan | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-technical-support-engineer-integration-tokyo-japan-819907/\n",
      "009. Teamcenter Systems Administrator (Onsite) | Houston, TX, United States | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/teamcenter-systems-administrator-onsite-houston-tx-united-states-820021/\n",
      "010. Database Engineer- Sr. Consultant level- NoSQL | Highlands Ranch, CO, United States | 4h ago | USD 135K-196K\n",
      "     https://foorilla.com/hiring/jobs/database-engineer-sr-consultant-level-nosql-highlands-ranch-co-united-states-819714/\n",
      "011. Software Engineer OOP (Hybrid) | Ciudad de México, DIF, Mexico | 4h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-engineer-oop-hybrid-ciudad-de-mexico-dif-mexico-819782/\n",
      "012. Senior Solution Engineer, Insurance | Lehi, UT, United States | 5h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-solution-engineer-insurance-lehi-ut-united-states-820215/\n",
      "013. Service Now Developer | Medellín, Antioquia, Colombia | 5h ago | —\n",
      "     https://foorilla.com/hiring/jobs/service-now-developer-medellin-antioquia-colombia-820203/\n",
      "014. Cloud Infrastructure Engineer - Hybrid Tempe | Tempe, AZ, United States | 5h ago | —\n",
      "     https://foorilla.com/hiring/jobs/cloud-infrastructure-engineer-hybrid-tempe-tempe-az-united-states-819662/\n",
      "015. Cybersecurity Engineer, M&A Automation | Austin, TX, United States | 5h ago | USD 116K-164K\n",
      "     https://foorilla.com/hiring/jobs/cybersecurity-engineer-ma-automation-austin-tx-united-states-819668/\n",
      "016. Senior Data Scientist | Herndon, VA, United States | 5h ago | USD 117K-165K\n",
      "     https://foorilla.com/hiring/jobs/senior-data-scientist-herndon-va-united-states-819701/\n",
      "017. Staff Software Engineer | Santa Clara, CA, United States | 5h ago | USD 149K-204K\n",
      "     https://foorilla.com/hiring/jobs/staff-software-engineer-santa-clara-ca-united-states-819783/\n",
      "018. Software Engineer | Overland Park, KS, United States | 5h ago | USD 85K-110K\n",
      "     https://foorilla.com/hiring/jobs/software-engineer-overland-park-ks-united-states-819784/\n",
      "019. Consultant- Data Analyst | New York, NY, United States | 6h ago | USD 88K-108K\n",
      "     https://foorilla.com/hiring/jobs/consultant-data-analyst-new-york-ny-united-states-819675/\n",
      "020. Senior Data Engineer II | New York, NY, United States[R] | 6h ago | USD 130K-160K\n",
      "     https://foorilla.com/hiring/jobs/senior-data-engineer-ii-new-york-ny-united-states-819690/\n",
      "021. Senior Software Engineer II , Retail Pricing | New York, NY, United States[R] | 6h ago | USD 130K-160K\n",
      "     https://foorilla.com/hiring/jobs/senior-software-engineer-ii-retail-pricing-new-york-ny-united-states-819785/\n",
      "022. Senior Software Engineer II, Commercial & Wealth | New York, NY, United States[R] | 6h ago | USD 130K-160K\n",
      "     https://foorilla.com/hiring/jobs/senior-software-engineer-ii-commercial-wealth-new-york-ny-united-states-819786/\n",
      "023. Staff Full-Stack Software Engineer, Dev Agent Tools | Santa Clara, California, United States | 6h ago | USD 163K-286K\n",
      "     https://foorilla.com/hiring/jobs/staff-full-stack-software-engineer-dev-agent-tools-santa-clara-california-united-states-819737/\n",
      "024. Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience | Seattle, WA, United States | 6h ago | USD 85K-135K\n",
      "     https://foorilla.com/hiring/jobs/business-analyst-ii-data-compliance-analyst-ii-legacy-is-operational-experience-seattle-wa-united-states-819979/\n",
      "025. Staff Software Engineer, Lending | Reading, UNITED KINGDOM, United Kingdom[R] | 6h ago | —\n",
      "     https://foorilla.com/hiring/jobs/staff-software-engineer-lending-reading-united-kingdom-united-kingdom-819787/\n",
      "026. Staff Software Engineer, Tokenization | Austin, TX, United States[R] | 6h ago | USD 110K-162K\n",
      "     https://foorilla.com/hiring/jobs/staff-software-engineer-tokenization-austin-tx-united-states-819788/\n",
      "027. Senior Staff Test Engineer / Team Leader | Austin, TEXAS, United States | 6h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-staff-test-engineer-team-leader-austin-texas-united-states-820022/\n",
      "028. AI Research Engineer- Advanced Driving Assistance Systems (ADAS) | Sunnyvale, CA, United States | 7h ago | USD 165K-200K\n",
      "     https://foorilla.com/hiring/jobs/ai-research-engineer-advanced-driving-assistance-systems-adas-sunnyvale-ca-united-states-819637/\n",
      "029. Associate Solutions Designer | Highlands Ranch, CO, United States | 7h ago | USD 79K-113K\n",
      "     https://foorilla.com/hiring/jobs/associate-solutions-designer-highlands-ranch-co-united-states-819929/\n",
      "030. Principal Engineer Software (Prisma Access) - NetSec | Pune, MH, India | 7h ago | —\n",
      "     https://foorilla.com/hiring/jobs/principal-engineer-software-prisma-access-netsec-pune-mh-india-819748/\n",
      "031. Backend Engineer | Montevideo, URUGUAY, Uruguay | 7h ago | —\n",
      "     https://foorilla.com/hiring/jobs/backend-engineer-montevideo-uruguay-uruguay-819655/\n",
      "032. Staff Engineer Software (Prisma Access)- NetSec | Pune, MH, India | 7h ago | —\n",
      "     https://foorilla.com/hiring/jobs/staff-engineer-software-prisma-access-netsec-pune-mh-india-819749/\n",
      "033. Solutions Consultant 2 - FSI | Reston, VA, United States | 7h ago | USD 198K-313K\n",
      "     https://foorilla.com/hiring/jobs/solutions-consultant-2-fsi-reston-va-united-states-819930/\n",
      "034. Cybersecurity Engineer - GRC | Austin, TX, United States | 8h ago | USD 116K-164K\n",
      "     https://foorilla.com/hiring/jobs/cybersecurity-engineer-grc-austin-tx-united-states-819669/\n",
      "035. Senior Staff Software Engineer (Cloud NW & AI Security) | Santa Clara, CA, United States | 8h ago | USD 126K-204K\n",
      "     https://foorilla.com/hiring/jobs/senior-staff-software-engineer-cloud-nw-ai-security-santa-clara-ca-united-states-819789/\n",
      "036. Desarrollador Backend Java Semisenior | Bogotá, Bogota, Colombia | 8h ago | —\n",
      "     https://foorilla.com/hiring/jobs/desarrollador-backend-java-semisenior-bogota-bogota-colombia-819739/\n",
      "037. Technical Enablement Specialist - NetSec | Plano, TX, United States | 8h ago | —\n",
      "     https://foorilla.com/hiring/jobs/technical-enablement-specialist-netsec-plano-tx-united-states-819750/\n",
      "038. Senior Identity Security Services Engineer | Chicago, US-IL, United States | 8h ago | USD 90K-132K\n",
      "     https://foorilla.com/hiring/jobs/senior-identity-security-services-engineer-chicago-us-il-united-states-820023/\n",
      "039. Data Insights Engineer | Foster City, CA, United States | 8h ago | USD 124K-180K\n",
      "     https://foorilla.com/hiring/jobs/data-insights-engineer-foster-city-ca-united-states-820024/\n",
      "040. Industrial Engineer | Greensboro, NC, United States | 8h ago | —\n",
      "     https://foorilla.com/hiring/jobs/industrial-engineer-greensboro-nc-united-states-820261/\n",
      "041. Creative Graphic Engineer - AI & Design | Pune, MH, India | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/creative-graphic-engineer-ai-design-pune-mh-india-820188/\n",
      "042. Conversational AI Developer (Google CCAI / AWS) | All cities, India | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/conversational-ai-developer-google-ccai-aws-all-cities-india-819635/\n",
      "043. Senior Software Engineer | Hyderabad, India | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-software-engineer-hyderabad-india-819790/\n",
      "044. Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance | Foster City, CA, United States | 9h ago | USD 174K-253K\n",
      "     https://foorilla.com/hiring/jobs/cyber-security-engineer-sr-consultant-level-regulatory-audit-compliance-foster-city-ca-united-states-819663/\n",
      "045. Engineer, Software Development Engineering (Apps) | Bengaluru, KA, India | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/engineer-software-development-engineering-apps-bengaluru-ka-india-819771/\n",
      "046. MID Software Engineer / Fullstack | Bogota, DC, Colombia | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/mid-software-engineer-fullstack-bogota-dc-colombia-819727/\n",
      "047. Data Governance Specialist | São Paulo, SP, Brazil | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/data-governance-specialist-sao-paulo-sp-brazil-820025/\n",
      "048. Data Governance Specialist | Buenos Aires, Buenos Aires, Argentina | 9h ago | —\n",
      "     https://foorilla.com/hiring/jobs/data-governance-specialist-buenos-aires-buenos-aires-argentina-820026/\n",
      "049. Sr Dir PM, Data & Analytics | Santa Clara, CALIFORNIA, United States | 9h ago | USD 250K-437K\n",
      "     https://foorilla.com/hiring/jobs/sr-dir-pm-data-analytics-santa-clara-california-united-states-819639/\n",
      "050. Senior Data Engineer I | New York, NY, United States[R] | 10h ago | USD 110K-130K\n",
      "     https://foorilla.com/hiring/jobs/senior-data-engineer-i-new-york-ny-united-states-819691/\n",
      "051. Senior Technical Marketing Engineer (SASE) | Santa Clara, CA, United States | 10h ago | USD 134K-215K\n",
      "     https://foorilla.com/hiring/jobs/senior-technical-marketing-engineer-sase-santa-clara-ca-united-states-819931/\n",
      "052. Sr Software Engineer Backend | Buenos Aires, Argentina | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/sr-software-engineer-backend-buenos-aires-argentina-819791/\n",
      "053. C++ Software Engineer - Trading applications | New York, NY, United States | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/c-software-engineer-trading-applications-new-york-ny-united-states-819792/\n",
      "054. Senior C++ Developer | Córdoba, Córdoba Province, Argentina | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-c-developer-cordoba-cordoba-province-argentina-819980/\n",
      "055. Staff Software Engineer | London, United Kingdom | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/staff-software-engineer-london-united-kingdom-819793/\n",
      "056. Scientific Data Analyst | Vaughan, ON, Canada | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/scientific-data-analyst-vaughan-on-canada-819676/\n",
      "057. Sr Production Service Engineer - Cloud Operations - Federal | Orlando, Florida, United States | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/sr-production-service-engineer-cloud-operations-federal-orlando-florida-united-states-819932/\n",
      "058. Network Systems Engineer (Pre-Sales) | Detroit, MI, United States | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/network-systems-engineer-pre-sales-detroit-mi-united-states-820262/\n",
      "059. Senior Solutions Engineer, PAM | Boston, US-MA, United States | 10h ago | USD 119K-175K\n",
      "     https://foorilla.com/hiring/jobs/senior-solutions-engineer-pam-boston-us-ma-united-states-819902/\n",
      "060. Principal Software Engineer (Intrusion Prevention System Development) | Santa Clara, CA, United States | 10h ago | —\n",
      "     https://foorilla.com/hiring/jobs/principal-software-engineer-intrusion-prevention-system-development-santa-clara-ca-united-states-819794/\n",
      "061. Senior Engineering Manager – Data Science (Pricing & Fleet Optimization) (m/f/d) | Lisbon, Portugal | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-engineering-manager-data-science-pricing-fleet-optimization-mfd-lisbon-portugal-819702/\n",
      "062. Ops Test Analyst - China Lake CA | Ridgecrest, CA, United States | 11h ago | USD 83K-132K\n",
      "     https://foorilla.com/hiring/jobs/ops-test-analyst-china-lake-ca-ridgecrest-ca-united-states-819212/\n",
      "063. Senior Data Engineer | Philadelphia, PA, United States | 11h ago | USD 80K-100K\n",
      "     https://foorilla.com/hiring/jobs/senior-data-engineer-philadelphia-pa-united-states-819692/\n",
      "064. Backup and Recovery Administrator | Huntington, WV, United States | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/backup-and-recovery-administrator-huntington-wv-united-states-818641/\n",
      "065. Senior Genesys Cloud CX Consultant | All cities, India[R] | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-genesys-cloud-cx-consultant-all-cities-india-819933/\n",
      "066. Product Marketing Manager | Staines, england, United Kingdom | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/product-marketing-manager-staines-england-united-kingdom-818642/\n",
      "067. Associate Software Engineer | Bristol, United Kingdom | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/associate-software-engineer-bristol-united-kingdom-818578/\n",
      "068. Associate Flood Modeller / Hydrologist | Brisbane, QLD, AU | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/associate-flood-modeller-hydrologist-brisbane-qld-au-818813/\n",
      "069. Senior Manager, Retail Analytics | Pittsburgh, PA, United States | 11h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-manager-retail-analytics-pittsburgh-pa-united-states-818450/\n",
      "070. Cyber Threat Analyst 1 | Fairfax, VA, United States | 12h ago | —\n",
      "     https://foorilla.com/hiring/jobs/cyber-threat-analyst-1-fairfax-va-united-states-818643/\n",
      "071. Développeur Fullstack PHP Symfony / React senior H/F | Valbonne, Provence-Alpes-Côte d'Azur, France | 12h ago | —\n",
      "     https://foorilla.com/hiring/jobs/developpeur-fullstack-php-symfony-react-senior-hf-valbonne-provence-alpes-cote-dazur-france-819728/\n",
      "072. Engineer II, Golang - (Logistics, Deliveries) | Berlin, Germany | 12h ago | —\n",
      "     https://foorilla.com/hiring/jobs/engineer-ii-golang-logistics-deliveries-berlin-germany-819738/\n",
      "073. Senior BI Engineer | Hybrid (08005, Barcelona, Barcelona, Spain) | 12h ago | EUR 50K-53K\n",
      "     https://foorilla.com/hiring/jobs/senior-bi-engineer-hybrid-08005-barcelona-barcelona-spain-818474/\n",
      "074. Software Engineer-Python | DevOps | Cloud | All cities, India | 12h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-engineer-python-devops-cloud-all-cities-india-819718/\n",
      "075. Director, Data Science, Visa Consulting & Analytics, India and South Asia | Mumbai, INDIA, India | 12h ago | —\n",
      "     https://foorilla.com/hiring/jobs/director-data-science-visa-consulting-analytics-india-and-south-asia-mumbai-india-india-819640/\n",
      "076. Staff Product Security Engineer | Petah Tikva, Israel | 12h ago | —\n",
      "     https://foorilla.com/hiring/jobs/staff-product-security-engineer-petah-tikva-israel-819769/\n",
      "077. Senior Data Engineer (Pipelines & Ingestion) (f/m/d) - Metrify Smart Metering | Berlin, BE, Germany | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-data-engineer-pipelines-ingestion-fmd-metrify-smart-metering-berlin-be-germany-819693/\n",
      "078. Algorithm Engineer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/algorithm-engineer-tel-aviv-yafo-tel-aviv-district-il-818400/\n",
      "079. Senior Data Engineer | Buenos Aires, Buenos Aires, Argentina | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-data-engineer-buenos-aires-buenos-aires-argentina-819694/\n",
      "080. Software Engineer IV | Annapolis Junction, MD | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-engineer-iv-annapolis-junction-md-818579/\n",
      "081. Software Engineer III | Annapolis Junction, MD | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-engineer-iii-annapolis-junction-md-818580/\n",
      "082. AI Engineer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/ai-engineer-tel-aviv-yafo-tel-aviv-district-il-818378/\n",
      "083. Alternance – Data analyst F/H | Ile-de-France, Yvelines (78) | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/alternance-data-analyst-fh-ile-de-france-yvelines-78-818861/\n",
      "084. Associate AI Engineer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/associate-ai-engineer-tel-aviv-yafo-tel-aviv-district-il-818379/\n",
      "085. Enterprise Account Executive, IL | Tel Aviv-Jaffa, Tel Aviv District, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/enterprise-account-executive-il-tel-aviv-jaffa-tel-aviv-district-il-818330/\n",
      "086. Chef de projet MOE H/F | France, Ile-de-France, Seine Saint-Denis (93) | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/chef-de-projet-moe-hf-france-ile-de-france-seine-saint-denis-93-819440/\n",
      "087. Website Content Manager | Kyiv, Kyiv, UA[R] | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/website-content-manager-kyiv-kyiv-ua-818338/\n",
      "088. Backend Engineer Golang  (f|m|d) (100%) - Sophia-Antipolis - Hybrid or Remote working model | Valbonne, France[R] | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/backend-engineer-golang-fmd-100-sophia-antipolis-hybrid-or-remote-working-model-valbonne-france-819656/\n",
      "089. Web Designer | Tel Aviv-Yafo, Tel Aviv District, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/web-designer-tel-aviv-yafo-tel-aviv-district-il-818645/\n",
      "090. IT Infrastructure Director | Herzliya, Tel-Aviv district, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/it-infrastructure-director-herzliya-tel-aviv-district-il-818616/\n",
      "091. Site Reliability Developer 4 | India | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/site-reliability-developer-4-india-818093/\n",
      "092. Technical Product Manager | Ramat Gan, Israel, IL | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/technical-product-manager-ramat-gan-israel-il-818646/\n",
      "093. Senior Data Scientist | Dublin, County Dublin, Ireland | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-data-scientist-dublin-county-dublin-ireland-819703/\n",
      "094. Mitarbeiter:in Data Science & Customer Support Freiburg im Breisgau oder Aachen, Deutschland | Freiburg im Breisgau, Germany | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/mitarbeiterin-data-science-customer-support-freiburg-im-breisgau-oder-aachen-deutschland-freiburg-im-breisgau-germany-818002/\n",
      "095. Product Owner DATA | Rabat, Morocco | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/product-owner-data-rabat-morocco-819934/\n",
      "096. Software Engineer with PHP, Symfony Framework  & DB experience | Mumbai, MH, India | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/software-engineer-with-php-symfony-framework-db-experience-mumbai-mh-india-819795/\n",
      "097. Site Reliability Engineer | Athens, Athens, GR | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/site-reliability-engineer-athens-athens-gr-818566/\n",
      "098. Senior Software Architect | San Sebastian, Gipuzkoa, ES | 13h ago | —\n",
      "     https://foorilla.com/hiring/jobs/senior-software-architect-san-sebastian-gipuzkoa-es-818647/\n",
      "099. Data & Reporting System(s) Coordinator | Hoffman Estates, IL, United States | 13h ago | USD 62K-68K\n",
      "     https://foorilla.com/hiring/jobs/data-reporting-systems-coordinator-hoffman-estates-il-united-states-818648/\n",
      "100. Data & Reporting System(s) Coordinator | Hoffman Estates, IL, United States | 13h ago | USD 62K-68K\n",
      "     https://foorilla.com/hiring/jobs/data-reporting-systems-coordinator-hoffman-estates-il-united-states-818649/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "LIST = f\"{BASE}/hiring/jobs/\"\n",
    "\n",
    "UA = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/124.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "def get_csrf_and_session():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": UA})\n",
    "    r = s.get(START, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    body = soup.find(\"body\")\n",
    "    # The page sets hx-headers via a JS expression in the body tag.\n",
    "    # We’ll scrape the CSRF token from there if present; otherwise continue without it.\n",
    "    csrf = None\n",
    "    body_str = str(body) if body else \"\"\n",
    "    m = re.search(r'\"X-CSRFToken\"\\s*:\\s*\"([^\"]+)\"', body_str)\n",
    "    if m:\n",
    "        csrf = m.group(1)\n",
    "    return s, csrf\n",
    "\n",
    "def get_list_page(session, page=None, csrf=None):\n",
    "    # HTMX-style headers the backend expects\n",
    "    hdrs = {\n",
    "        \"User-Agent\": UA,\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": START,\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": \"mc_1\",\n",
    "        \"HX-Current-URL\": START,\n",
    "        # The site sets \"X-Screen\" to 'M' (mobile) or 'D' (desktop) via JS.\n",
    "        # We can just send 'D' so we get desktop list markup.\n",
    "        \"X-Screen\": \"D\",\n",
    "    }\n",
    "    if csrf:\n",
    "        hdrs[\"X-CSRFToken\"] = csrf\n",
    "\n",
    "    url = LIST if not page or page == 1 else f\"{LIST}?page={page}\"\n",
    "    r = session.get(url, headers=hdrs, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_jobs(soup):\n",
    "    jobs = []\n",
    "    rows = soup.select(\"li.list-group-item\")\n",
    "    for row in rows:\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a:\n",
    "            continue\n",
    "        title = a.get_text(strip=True)\n",
    "        hx_get = a.get(\"hx-get\")  # detail endpoint lives here\n",
    "        url = urljoin(BASE, hx_get) if hx_get else None\n",
    "\n",
    "        time_ago_el = row.select_one(\".hstack .flex-shrink-0.text-body-secondary small\")\n",
    "        time_ago = time_ago_el.get_text(strip=True) if time_ago_el else None\n",
    "\n",
    "        loc_el = row.select_one(\".hstack .text-end small\")\n",
    "        location = loc_el.get_text(strip=True) if loc_el else None\n",
    "\n",
    "        sal_el = row.select_one(\".text-success-emphasis\")\n",
    "        salary = sal_el.get_text(strip=True) if sal_el else None\n",
    "\n",
    "        jobs.append({\n",
    "            \"title\": title or None,\n",
    "            \"url\": url,\n",
    "            \"location\": location or None,\n",
    "            \"time_ago\": time_ago or None,\n",
    "            \"salary\": salary or None,\n",
    "        })\n",
    "    return jobs\n",
    "\n",
    "def scrape_all_jobs(max_pages=None, pause=0.5):\n",
    "    session, csrf = get_csrf_and_session()\n",
    "    all_jobs = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        soup = get_list_page(session, page=page, csrf=csrf)\n",
    "        chunk = parse_jobs(soup)\n",
    "        if not chunk:\n",
    "            break\n",
    "        all_jobs.extend(chunk)\n",
    "\n",
    "        # If there’s another page, there will usually be a sentinel li with hx-get=\"?page=N\"\n",
    "        # We can just try the next integer page; stop when empty.\n",
    "        page += 1\n",
    "        if max_pages and page > max_pages:\n",
    "            break\n",
    "        time.sleep(pause)  # be polite\n",
    "\n",
    "    # de-duplicate by URL\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for j in all_jobs:\n",
    "        key = j.get(\"url\")\n",
    "        if key and key not in seen:\n",
    "            seen.add(key)\n",
    "            unique.append(j)\n",
    "    return unique\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jobs = scrape_all_jobs()  # add max_pages=3 to test quickly\n",
    "    print(f\"Collected {len(jobs)} jobs\")\n",
    "    for i, j in enumerate(jobs, 1):\n",
    "        print(f\"{i:03d}. {j['title']} | {j.get('location') or '—'} | {j.get('time_ago') or '—'} | {j.get('salary') or '—'}\")\n",
    "        print(f\"     {j['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47859e98-db20-445b-ac58-4bd5a7377642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "\n",
      "✅ Extracted 100 job details.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "LIST = f\"{BASE}/hiring/jobs/\"\n",
    "\n",
    "UA = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/124.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "def get_csrf_and_session():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": UA})\n",
    "    r = s.get(START, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    body_str = str(soup.find(\"body\") or \"\")\n",
    "    m = re.search(r'\"X-CSRFToken\"\\s*:\\s*\"([^\"]+)\"', body_str)\n",
    "    csrf = m.group(1) if m else None\n",
    "    return s, csrf\n",
    "\n",
    "def get_list_page(session, page=None, csrf=None):\n",
    "    hdrs = {\n",
    "        \"User-Agent\": UA,\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": START,\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": \"mc_1\",\n",
    "        \"HX-Current-URL\": START,\n",
    "        \"X-Screen\": \"D\",\n",
    "    }\n",
    "    if csrf:\n",
    "        hdrs[\"X-CSRFToken\"] = csrf\n",
    "    url = LIST if not page or page == 1 else f\"{LIST}?page={page}\"\n",
    "    r = session.get(url, headers=hdrs, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_jobs(soup):\n",
    "    jobs = []\n",
    "    rows = soup.select(\"li.list-group-item\")\n",
    "    for row in rows:\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a:\n",
    "            continue\n",
    "        title = a.get_text(strip=True)\n",
    "        hx_get = a.get(\"hx-get\")\n",
    "        url = urljoin(BASE, hx_get) if hx_get else None\n",
    "        jobs.append({\"title\": title or None, \"url\": url})\n",
    "    return jobs\n",
    "\n",
    "def extract_job_info(job_url):\n",
    "    \"\"\"Extract full job details from its detail page.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(job_url, headers={\"User-Agent\": UA}, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        job_title = soup.select_one(\"h1\").get_text(strip=True) if soup.select_one(\"h1\") else None\n",
    "        company = soup.select_one(\".text-body-secondary a\")\n",
    "        company_name = company.get_text(strip=True) if company else None\n",
    "        description_el = soup.select_one(\".job-description\") or soup.select_one(\".lead\")\n",
    "        description = description_el.get_text(strip=True) if description_el else None\n",
    "\n",
    "        return {\n",
    "            \"job_title\": job_title,\n",
    "            \"company\": company_name,\n",
    "            \"description\": description,\n",
    "            \"url\": job_url\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {job_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_all_jobs(max_pages=None, pause=0.5):\n",
    "    session, csrf = get_csrf_and_session()\n",
    "    all_jobs = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        soup = get_list_page(session, page=page, csrf=csrf)\n",
    "        chunk = parse_jobs(soup)\n",
    "        if not chunk:\n",
    "            break\n",
    "        all_jobs.extend(chunk)\n",
    "        page += 1\n",
    "        if max_pages and page > max_pages:\n",
    "            break\n",
    "        time.sleep(pause)\n",
    "    return all_jobs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_listings = scrape_all_jobs()\n",
    "    job_info_list = []\n",
    "\n",
    "    for job in job_listings:\n",
    "        job_url = job.get(\"url\")\n",
    "        if not job_url:\n",
    "            continue\n",
    "        job_info = extract_job_info(job_url)\n",
    "        try:\n",
    "            print(job_info[\"job_title\"])\n",
    "            job_info_list.append(job_info)\n",
    "        except Exception:\n",
    "            print(f\"Could not extract info from: {job_url}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n✅ Extracted {len(job_info_list)} job details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c54efffb-d5cc-485b-8d72-71decffb4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 listings\n",
      "Software Development Engineer 2-6\n",
      "IT Infrastructure Engineer\n",
      "Senior Software Engineer\n",
      "Software System Engineer\n",
      "Junior Automation Tester\n",
      "Staff Facilities Engineer (Electrical)\n",
      "Java Fullstack Developer - 2-4 Years\n",
      "Senior Technical Support Engineer (Integration)\n",
      "Teamcenter Systems Administrator (Onsite)\n",
      "Database Engineer- Sr. Consultant level- NoSQL\n",
      "Software Engineer OOP (Hybrid)\n",
      "Senior Solution Engineer, Insurance\n",
      "Service Now Developer\n",
      "Cloud Infrastructure Engineer - Hybrid Tempe\n",
      "Cybersecurity Engineer, M&A Automation\n",
      "Senior Data Scientist\n",
      "Staff Software Engineer\n",
      "Software Engineer\n",
      "Consultant- Data Analyst\n",
      "Senior Data Engineer II\n",
      "Senior Software Engineer II , Retail Pricing\n",
      "Senior Software Engineer II, Commercial & Wealth\n",
      "Staff Full-Stack Software Engineer, Dev Agent Tools\n",
      "Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience\n",
      "Staff Software Engineer, Lending\n",
      "Staff Software Engineer, Tokenization\n",
      "Senior Staff Test Engineer / Team Leader\n",
      "AI Research Engineer- Advanced Driving Assistance Systems (ADAS)\n",
      "Associate Solutions Designer\n",
      "Principal Engineer Software (Prisma Access) - NetSec\n",
      "Backend Engineer\n",
      "Staff Engineer Software (Prisma Access)- NetSec\n",
      "Solutions Consultant 2 - FSI\n",
      "Cybersecurity Engineer - GRC\n",
      "Senior Staff Software Engineer (Cloud NW & AI Security)\n",
      "Desarrollador Backend Java Semisenior\n",
      "Technical Enablement Specialist - NetSec\n",
      "Senior Identity Security Services Engineer\n",
      "Data Insights Engineer\n",
      "Industrial Engineer\n",
      "Creative Graphic Engineer - AI & Design\n",
      "Conversational AI Developer (Google CCAI / AWS)\n",
      "Senior Software Engineer\n",
      "Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance\n",
      "Engineer, Software Development Engineering (Apps)\n",
      "MID Software Engineer / Fullstack\n",
      "Data Governance Specialist\n",
      "Data Governance Specialist\n",
      "Sr Dir PM, Data & Analytics\n",
      "Senior Data Engineer I\n",
      "Senior Technical Marketing Engineer (SASE)\n",
      "Sr Software Engineer Backend\n",
      "C++ Software Engineer - Trading applications\n",
      "Senior C++ Developer\n",
      "Staff Software Engineer\n",
      "Scientific Data Analyst\n",
      "Sr Production Service Engineer - Cloud Operations - Federal\n",
      "Network Systems Engineer (Pre-Sales)\n",
      "Senior Solutions Engineer, PAM\n",
      "Principal Software Engineer (Intrusion Prevention System Development)\n",
      "Senior Engineering Manager – Data Science (Pricing & Fleet Optimization) (m/f/d)\n",
      "Ops Test Analyst - China Lake CA\n",
      "Senior Data Engineer\n",
      "Backup and Recovery Administrator\n",
      "Senior Genesys Cloud CX Consultant\n",
      "Product Marketing Manager\n",
      "Associate Software Engineer\n",
      "Associate Flood Modeller / Hydrologist\n",
      "Senior Manager, Retail Analytics\n",
      "Cyber Threat Analyst 1\n",
      "Développeur Fullstack PHP Symfony / React senior H/F\n",
      "Engineer II, Golang - (Logistics, Deliveries)\n",
      "Senior BI Engineer\n",
      "Software Engineer-Python | DevOps | Cloud\n",
      "Director, Data Science, Visa Consulting & Analytics, India and South Asia\n",
      "Staff Product Security Engineer\n",
      "Senior Data Engineer (Pipelines & Ingestion) (f/m/d) - Metrify Smart Metering\n",
      "Algorithm Engineer\n",
      "Senior Data Engineer\n",
      "Software Engineer IV\n",
      "Software Engineer III\n",
      "AI Engineer\n",
      "Alternance – Data analyst F/H\n",
      "Associate AI Engineer\n",
      "Enterprise Account Executive, IL\n",
      "Chef de projet MOE H/F\n",
      "Website Content Manager\n",
      "Backend Engineer Golang  (f|m|d) (100%) - Sophia-Antipolis - Hybrid or Remote working model\n",
      "Web Designer\n",
      "IT Infrastructure Director\n",
      "Site Reliability Developer 4\n",
      "Technical Product Manager\n",
      "Senior Data Scientist\n",
      "Mitarbeiter:in Data Science & Customer Support Freiburg im Breisgau oder Aachen, Deutschland\n",
      "Product Owner DATA\n",
      "Software Engineer with PHP, Symfony Framework  & DB experience\n",
      "Site Reliability Engineer\n",
      "Senior Software Architect\n",
      "Data & Reporting System(s) Coordinator\n",
      "Data & Reporting System(s) Coordinator\n",
      "\n",
      "✅ Extracted 100 job details.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "LIST  = f\"{BASE}/hiring/jobs/\"\n",
    "\n",
    "UA = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/124.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "def get_session_and_csrf():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": UA})\n",
    "    r = s.get(START, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    body = soup.find(\"body\")\n",
    "    csrf = None\n",
    "    if body:\n",
    "        m = re.search(r'\"X-CSRFToken\"\\s*:\\s*\"([^\"]+)\"', str(body))\n",
    "        if m:\n",
    "            csrf = m.group(1)\n",
    "    return s, csrf\n",
    "\n",
    "def htmx_headers(csrf=None, target=\"mc_1\"):\n",
    "    hdrs = {\n",
    "        \"User-Agent\": UA,\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": START,\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": target,\n",
    "        \"HX-Current-URL\": START,\n",
    "        \"X-Screen\": \"D\",\n",
    "    }\n",
    "    if csrf:\n",
    "        hdrs[\"X-CSRFToken\"] = csrf\n",
    "    return hdrs\n",
    "\n",
    "def get_list_page(session, csrf, page=1):\n",
    "    url = LIST if page == 1 else f\"{LIST}?page={page}\"\n",
    "    r = session.get(url, headers=htmx_headers(csrf, target=\"mc_1\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_list_items(soup):\n",
    "    jobs = []\n",
    "    for row in soup.select(\"li.list-group-item\"):\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a:\n",
    "            continue\n",
    "        title = a.get_text(strip=True)\n",
    "        hx_get = a.get(\"hx-get\")  # detail endpoint (relative)\n",
    "        url = urljoin(BASE, hx_get) if hx_get else None\n",
    "\n",
    "        time_ago_el = row.select_one(\".hstack .flex-shrink-0.text-body-secondary small\")\n",
    "        time_ago = time_ago_el.get_text(strip=True) if time_ago_el else None\n",
    "\n",
    "        loc_el = row.select_one(\".hstack .text-end small\")\n",
    "        location = loc_el.get_text(strip=True) if loc_el else None\n",
    "\n",
    "        sal_el = row.select_one(\".text-success-emphasis\")\n",
    "        salary = sal_el.get_text(strip=True) if sal_el else None\n",
    "\n",
    "        jobs.append({\n",
    "            \"listing_title\": title or None,\n",
    "            \"url\": url,\n",
    "            \"listing_location\": location or None,\n",
    "            \"listing_time_ago\": time_ago or None,\n",
    "            \"listing_salary\": salary or None,\n",
    "        })\n",
    "    return jobs\n",
    "\n",
    "def extract_job_info(session, csrf, job_url):\n",
    "    \"\"\"\n",
    "    Fetch the job detail *fragment* with HTMX headers (target=mc_2),\n",
    "    then parse generously for title/company/description/apply link.\n",
    "    \"\"\"\n",
    "    r = session.get(job_url, headers=htmx_headers(csrf, target=\"mc_2\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    s = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Titles can be h1/h2/h3 or a prominent link\n",
    "    title_el = s.select_one(\"h1, h2, h3, .job-title, .card-title, .h3\")\n",
    "    job_title = title_el.get_text(strip=True) if title_el else None\n",
    "\n",
    "    # Company often shows in a muted text block with a link\n",
    "    company_el = s.select_one(\".text-body-secondary a, .company a, a[rel*=nofollow]\")\n",
    "    company = company_el.get_text(strip=True) if company_el else None\n",
    "\n",
    "    # Description: try a few common containers\n",
    "    desc_el = s.select_one(\".job-description, article, .content, .prose, .markdown, .card-body\")\n",
    "    description = desc_el.get_text(\" \", strip=True) if desc_el else None\n",
    "\n",
    "    # Apply link: look for obvious external links\n",
    "    apply_el = s.select_one(\"a[href*='apply'], a[href*='careers'], a[target='_blank']\")\n",
    "    apply_link = apply_el.get(\"href\") if apply_el else None\n",
    "    if apply_link and apply_link.startswith(\"/\"):\n",
    "        apply_link = urljoin(BASE, apply_link)\n",
    "\n",
    "    # Location/salary sometimes repeated in detail; fall back to listing if missing\n",
    "    loc_el = s.select_one(\".text-end small, .location, .badge:has(svg)\")\n",
    "    location = loc_el.get_text(strip=True) if loc_el else None\n",
    "\n",
    "    sal_el = s.select_one(\".text-success-emphasis, .salary, .badge.text-success-emphasis\")\n",
    "    salary = sal_el.get_text(strip=True) if sal_el else None\n",
    "\n",
    "    return {\n",
    "        \"job_title\": job_title,\n",
    "        \"company\": company,\n",
    "        \"description\": description,\n",
    "        \"apply_link\": apply_link,\n",
    "        \"location\": location,\n",
    "        \"salary\": salary,\n",
    "        \"detail_url\": job_url,\n",
    "    }\n",
    "\n",
    "def scrape_all_jobs(max_pages=None, pause=0.5):\n",
    "    session, csrf = get_session_and_csrf()\n",
    "    all_jobs = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        soup = get_list_page(session, csrf, page=page)\n",
    "        chunk = parse_list_items(soup)\n",
    "        if not chunk:\n",
    "            break\n",
    "        all_jobs.extend(chunk)\n",
    "        page += 1\n",
    "        if max_pages and page > max_pages:\n",
    "            break\n",
    "        time.sleep(pause)\n",
    "    return session, csrf, all_jobs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) collect all listing URLs via HTMX\n",
    "    session, csrf, job_listings = scrape_all_jobs()\n",
    "    print(f\"Found {len(job_listings)} listings\")\n",
    "\n",
    "    # 2) your requested loop to fetch & store detail info\n",
    "    job_info_list = []\n",
    "    for j in job_listings:\n",
    "        job_url = j.get(\"url\")\n",
    "        if not job_url:\n",
    "            continue\n",
    "        info = extract_job_info(session, csrf, job_url)\n",
    "        # merge list metadata with detail info, and print title\n",
    "        if info and info.get(\"job_title\"):\n",
    "            info.update({\n",
    "                \"listing_title\": j.get(\"listing_title\"),\n",
    "                \"listing_location\": j.get(\"listing_location\"),\n",
    "                \"listing_time_ago\": j.get(\"listing_time_ago\"),\n",
    "                \"listing_salary\": j.get(\"listing_salary\"),\n",
    "            })\n",
    "            print(info[\"job_title\"])\n",
    "            job_info_list.append(info)\n",
    "        else:\n",
    "            print(f\"Could not extract info from: {job_url}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n✅ Extracted {len(job_info_list)} job details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3df35282-e361-4845-a170-4aa21f4e6276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>apply_link</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>detail_url</th>\n",
       "      <th>listing_title</th>\n",
       "      <th>listing_location</th>\n",
       "      <th>listing_time_ago</th>\n",
       "      <th>listing_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software Development Engineer 2-6</td>\n",
       "      <td>@ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/crahcVTeWfYpX...</td>\n",
       "      <td>India - Bangalore - Remote Office[R]</td>\n",
       "      <td>USD 158K-210K</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/software-deve...</td>\n",
       "      <td>Software Development Engineer 2-6</td>\n",
       "      <td>India - Bangalore - Remote Office[R]</td>\n",
       "      <td>4h ago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT Infrastructure Engineer</td>\n",
       "      <td>@ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/huZ0Ey1wRFuF3...</td>\n",
       "      <td>Hong Kong, Hong Kong</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/it-infrastruc...</td>\n",
       "      <td>IT Infrastructure Engineer</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>4h ago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>@ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/vWTDGd6YSM6nm...</td>\n",
       "      <td>INBLR02 - Bangalore - Milesstone Buildcon, …</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/senior-softwa...</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>INBLR02 - Bangalore - Milesstone Buildcon, …</td>\n",
       "      <td>4h ago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software System Engineer</td>\n",
       "      <td>@ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/Pv3MdopQXSFpw...</td>\n",
       "      <td>Shenyang - PIC, China</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/software-syst...</td>\n",
       "      <td>Software System Engineer</td>\n",
       "      <td>Shenyang - PIC, China</td>\n",
       "      <td>4h ago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Automation Tester</td>\n",
       "      <td>@ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/CbBm2MRQuus8c...</td>\n",
       "      <td>UK - LONDON 25 ROPEMAKER STREET …</td>\n",
       "      <td>None</td>\n",
       "      <td>https://foorilla.com/hiring/jobs/junior-automa...</td>\n",
       "      <td>Junior Automation Tester</td>\n",
       "      <td>RO - BUCHAREST BULEVARDUL ION MIHALACHE …</td>\n",
       "      <td>4h ago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_title company description  \\\n",
       "0  Software Development Engineer 2-6   @ ...        None   \n",
       "1         IT Infrastructure Engineer   @ ...        None   \n",
       "2           Senior Software Engineer   @ ...        None   \n",
       "3           Software System Engineer   @ ...        None   \n",
       "4           Junior Automation Tester   @ ...        None   \n",
       "\n",
       "                                          apply_link  \\\n",
       "0  https://foorilla.com/hiring/jobs/crahcVTeWfYpX...   \n",
       "1  https://foorilla.com/hiring/jobs/huZ0Ey1wRFuF3...   \n",
       "2  https://foorilla.com/hiring/jobs/vWTDGd6YSM6nm...   \n",
       "3  https://foorilla.com/hiring/jobs/Pv3MdopQXSFpw...   \n",
       "4  https://foorilla.com/hiring/jobs/CbBm2MRQuus8c...   \n",
       "\n",
       "                                       location         salary  \\\n",
       "0          India - Bangalore - Remote Office[R]  USD 158K-210K   \n",
       "1                          Hong Kong, Hong Kong           None   \n",
       "2  INBLR02 - Bangalore - Milesstone Buildcon, …           None   \n",
       "3                         Shenyang - PIC, China           None   \n",
       "4             UK - LONDON 25 ROPEMAKER STREET …           None   \n",
       "\n",
       "                                          detail_url  \\\n",
       "0  https://foorilla.com/hiring/jobs/software-deve...   \n",
       "1  https://foorilla.com/hiring/jobs/it-infrastruc...   \n",
       "2  https://foorilla.com/hiring/jobs/senior-softwa...   \n",
       "3  https://foorilla.com/hiring/jobs/software-syst...   \n",
       "4  https://foorilla.com/hiring/jobs/junior-automa...   \n",
       "\n",
       "                       listing_title  \\\n",
       "0  Software Development Engineer 2-6   \n",
       "1         IT Infrastructure Engineer   \n",
       "2           Senior Software Engineer   \n",
       "3           Software System Engineer   \n",
       "4           Junior Automation Tester   \n",
       "\n",
       "                               listing_location listing_time_ago  \\\n",
       "0          India - Bangalore - Remote Office[R]           4h ago   \n",
       "1                                     Hong Kong           4h ago   \n",
       "2  INBLR02 - Bangalore - Milesstone Buildcon, …           4h ago   \n",
       "3                         Shenyang - PIC, China           4h ago   \n",
       "4     RO - BUCHAREST BULEVARDUL ION MIHALACHE …           4h ago   \n",
       "\n",
       "  listing_salary  \n",
       "0           None  \n",
       "1           None  \n",
       "2           None  \n",
       "3           None  \n",
       "4           None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(job_info_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68cdb865-2707-4107-8098-4eaa61a59212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 listings\n",
      "Software Development Engineer 2-6 @ ... None\n",
      "Junior Automation Tester @ ... None\n",
      "Staff Facilities Engineer (Electrical) @ ... None\n",
      "Senior Software Engineer @ ... None\n",
      "IT Infrastructure Engineer @ ... None\n",
      "Software System Engineer @ ... None\n",
      "Java Fullstack Developer - 2-4 Years @ ... None\n",
      "Senior Technical Support Engineer (Integration) @ ... None\n",
      "Teamcenter Systems Administrator (Onsite) @ ... None\n",
      "Database Engineer- Sr. Consultant level- NoSQL @ ... None\n",
      "Software Engineer OOP (Hybrid) @ ... None\n",
      "Senior Solution Engineer, Insurance @ ... None\n",
      "Service Now Developer @ ... None\n",
      "Cloud Infrastructure Engineer - Hybrid Tempe @ ... None\n",
      "Cybersecurity Engineer, M&A Automation @ ... None\n",
      "Senior Data Scientist @ ... None\n",
      "Staff Software Engineer @ ... None\n",
      "Software Engineer @ ... None\n",
      "Consultant- Data Analyst @ ... None\n",
      "Senior Data Engineer II @ ... None\n",
      "Senior Software Engineer II , Retail Pricing @ ... None\n",
      "Senior Software Engineer II, Commercial & Wealth @ ... None\n",
      "Staff Full-Stack Software Engineer, Dev Agent Tools @ ... None\n",
      "Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience @ ... None\n",
      "Staff Software Engineer, Lending @ ... None\n",
      "Staff Software Engineer, Tokenization @ ... None\n",
      "Senior Staff Test Engineer / Team Leader @ ... None\n",
      "AI Research Engineer- Advanced Driving Assistance Systems (ADAS) @ ... None\n",
      "Associate Solutions Designer @ ... None\n",
      "Principal Engineer Software (Prisma Access) - NetSec @ ... None\n",
      "Backend Engineer @ ... None\n",
      "Staff Engineer Software (Prisma Access)- NetSec @ ... None\n",
      "Solutions Consultant 2 - FSI @ ... None\n",
      "Cybersecurity Engineer - GRC @ ... None\n",
      "Senior Staff Software Engineer (Cloud NW & AI Security) @ ... None\n",
      "Desarrollador Backend Java Semisenior @ ... None\n",
      "Technical Enablement Specialist - NetSec @ ... None\n",
      "Senior Identity Security Services Engineer @ ... None\n",
      "Data Insights Engineer @ ... None\n",
      "Industrial Engineer @ ... None\n",
      "Creative Graphic Engineer - AI & Design @ ... None\n",
      "Conversational AI Developer (Google CCAI / AWS) @ ... None\n",
      "Senior Software Engineer @ ... None\n",
      "Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance @ ... None\n",
      "Engineer, Software Development Engineering (Apps) @ ... None\n",
      "MID Software Engineer / Fullstack @ ... None\n",
      "Data Governance Specialist @ ... None\n",
      "Data Governance Specialist @ ... None\n",
      "Sr Dir PM, Data & Analytics @ ... None\n",
      "Senior Data Engineer I @ ... None\n",
      "Senior Technical Marketing Engineer (SASE) @ ... None\n",
      "Sr Software Engineer Backend @ ... None\n",
      "C++ Software Engineer - Trading applications @ ... None\n",
      "Senior C++ Developer @ ... None\n",
      "Staff Software Engineer @ ... None\n",
      "Scientific Data Analyst @ ... None\n",
      "Sr Production Service Engineer - Cloud Operations - Federal @ ... None\n",
      "Network Systems Engineer (Pre-Sales) @ ... None\n",
      "Senior Solutions Engineer, PAM @ ... None\n",
      "Principal Software Engineer (Intrusion Prevention System Development) @ ... None\n",
      "Senior Engineering Manager – Data Science (Pricing & Fleet Optimization) (m/f/d) @ ... None\n",
      "Ops Test Analyst - China Lake CA @ ... None\n",
      "Senior Data Engineer @ ... None\n",
      "Backup and Recovery Administrator @ ... None\n",
      "Senior Genesys Cloud CX Consultant @ ... None\n",
      "Product Marketing Manager @ ... None\n",
      "Associate Software Engineer @ ... None\n",
      "Associate Flood Modeller / Hydrologist @ ... None\n",
      "Senior Manager, Retail Analytics @ ... None\n",
      "Cyber Threat Analyst 1 @ ... None\n",
      "Développeur Fullstack PHP Symfony / React senior H/F @ ... None\n",
      "Engineer II, Golang - (Logistics, Deliveries) @ ... None\n",
      "Senior BI Engineer @ ... None\n",
      "Software Engineer-Python | DevOps | Cloud @ ... None\n",
      "Director, Data Science, Visa Consulting & Analytics, India and South Asia @ ... None\n",
      "Staff Product Security Engineer @ ... None\n",
      "Senior Data Engineer (Pipelines & Ingestion) (f/m/d) - Metrify Smart Metering @ ... None\n",
      "Algorithm Engineer @ ... None\n",
      "Senior Data Engineer @ ... None\n",
      "Software Engineer IV @ ... None\n",
      "Software Engineer III @ ... None\n",
      "AI Engineer @ ... None\n",
      "Alternance – Data analyst F/H @ ... None\n",
      "Associate AI Engineer @ ... None\n",
      "Enterprise Account Executive, IL @ ... None\n",
      "Chef de projet MOE H/F @ ... None\n",
      "Website Content Manager @ ... None\n",
      "Backend Engineer Golang  (f|m|d) (100%) - Sophia-Antipolis - Hybrid or Remote working model @ ... None\n",
      "Web Designer @ ... None\n",
      "IT Infrastructure Director @ ... None\n",
      "Site Reliability Developer 4 @ ... None\n",
      "Technical Product Manager @ ... None\n",
      "Senior Data Scientist @ ... None\n",
      "Mitarbeiter:in Data Science & Customer Support Freiburg im Breisgau oder Aachen, Deutschland @ ... None\n",
      "Product Owner DATA @ ... None\n",
      "Software Engineer with PHP, Symfony Framework  & DB experience @ ... None\n",
      "Site Reliability Engineer @ ... None\n",
      "Senior Software Architect @ ... None\n",
      "Data & Reporting System(s) Coordinator @ ... None\n",
      "Data & Reporting System(s) Coordinator @ ... None\n",
      "\n",
      "✅ Extracted 100 job details.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "LIST  = f\"{BASE}/hiring/jobs/\"\n",
    "\n",
    "UA = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/124.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "def get_session_and_csrf():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": UA})\n",
    "    r = s.get(START, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    csrf = None\n",
    "    body = soup.find(\"body\")\n",
    "    if body:\n",
    "        m = re.search(r'\"X-CSRFToken\"\\s*:\\s*\"([^\"]+)\"', str(body))\n",
    "        if m: csrf = m.group(1)\n",
    "    return s, csrf\n",
    "\n",
    "def htmx_headers(csrf=None, target=\"mc_1\"):\n",
    "    hdrs = {\n",
    "        \"User-Agent\": UA,\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": START,\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": target,\n",
    "        \"HX-Current-URL\": START,\n",
    "        \"X-Screen\": \"D\",\n",
    "    }\n",
    "    if csrf:\n",
    "        hdrs[\"X-CSRFToken\"] = csrf\n",
    "    return hdrs\n",
    "\n",
    "def get_list_page(session, csrf, page=1):\n",
    "    url = LIST if page == 1 else f\"{LIST}?page={page}\"\n",
    "    r = session.get(url, headers=htmx_headers(csrf, target=\"mc_1\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_list_items(soup):\n",
    "    jobs = []\n",
    "    for row in soup.select(\"li.list-group-item\"):\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a: \n",
    "            continue\n",
    "        title = a.get_text(strip=True)\n",
    "        hx_get = a.get(\"hx-get\")\n",
    "        url = urljoin(BASE, hx_get) if hx_get else None\n",
    "        jobs.append({\"listing_title\": title or None, \"url\": url})\n",
    "    return jobs\n",
    "\n",
    "def _parse_json_ld_for_salary(soup):\n",
    "    \"\"\"\n",
    "    Look for <script type=\"application/ld+json\"> with JobPosting schema,\n",
    "    and extract baseSalary.value.minValue/maxValue if present.\n",
    "    \"\"\"\n",
    "    for script in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "        try:\n",
    "            data = json.loads(script.string or \"\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Sometimes it's a list of things\n",
    "        candidates = data if isinstance(data, list) else [data]\n",
    "        for obj in candidates:\n",
    "            if not isinstance(obj, dict):\n",
    "                continue\n",
    "            # Heuristics to find JobPosting nodes\n",
    "            t = obj.get(\"@type\")\n",
    "            if t == \"JobPosting\" or (isinstance(t, list) and \"JobPosting\" in t):\n",
    "                job_data = obj\n",
    "                salary_obj = (job_data.get(\"baseSalary\") or {}).get(\"value\") or {}\n",
    "                # Some sites use \"minValue\"/\"maxValue\"; others use \"value\" only\n",
    "                salary_min = salary_obj.get(\"minValue\")\n",
    "                salary_max = salary_obj.get(\"maxValue\")\n",
    "                if salary_min or salary_max:\n",
    "                    return salary_min, salary_max\n",
    "    return None, None\n",
    "\n",
    "def _parse_visible_salary_text(soup):\n",
    "    \"\"\"\n",
    "    Fallback: read visible salary text like 'USD 110K-162K' and map to min/max numbers (best effort).\n",
    "    Returns strings if parsing is uncertain.\n",
    "    \"\"\"\n",
    "    badge = soup.select_one(\".text-success-emphasis, .salary, .badge.text-success-emphasis\")\n",
    "    text = badge.get_text(\" \", strip=True) if badge else None\n",
    "    if not text:\n",
    "        return None, None\n",
    "\n",
    "    # Try to normalize formats like 'USD 110K-162K' or '$110,000–$162,000'\n",
    "    # Extract two numbers, allowing K/M suffix\n",
    "    m = re.findall(r'(\\d+(?:[\\d,]*)(?:\\.\\d+)?)([KkMm]?)', text)\n",
    "    vals = []\n",
    "    for num, suf in m:\n",
    "        n = float(num.replace(\",\", \"\"))\n",
    "        if suf.lower() == 'k':\n",
    "            n *= 1_000\n",
    "        elif suf.lower() == 'm':\n",
    "            n *= 1_000_000\n",
    "        vals.append(int(n))\n",
    "    if len(vals) >= 2:\n",
    "        return vals[0], vals[1]\n",
    "    return None, None\n",
    "\n",
    "def extract_job_info(session, csrf, job_url):\n",
    "    \"\"\"\n",
    "    Fetch the job detail fragment with HTMX headers (target=mc_2),\n",
    "    parse title/company/description, and salary_min/max as requested.\n",
    "    \"\"\"\n",
    "    r = session.get(job_url, headers=htmx_headers(csrf, target=\"mc_2\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    s = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Title\n",
    "    title_el = s.select_one(\"h1, h2, h3, .job-title, .card-title, .h3\")\n",
    "    job_title = title_el.get_text(strip=True) if title_el else None\n",
    "\n",
    "    # Company (best-effort)\n",
    "    company_el = s.select_one(\".text-body-secondary a, .company a, a[rel*=nofollow]\")\n",
    "    company_name = company_el.get_text(strip=True) if company_el else None\n",
    "\n",
    "    # Description\n",
    "    desc_el = s.select_one(\".job-description, article, .content, .prose, .markdown, .card-body\")\n",
    "    job_description = desc_el.get_text(\" \", strip=True) if desc_el else None\n",
    "\n",
    "    # Salary via JSON-LD first\n",
    "    salary_min, salary_max = _parse_json_ld_for_salary(s)\n",
    "    if salary_min is None and salary_max is None:\n",
    "        # Fallback to visible text badge\n",
    "        salary_min, salary_max = _parse_visible_salary_text(s)\n",
    "\n",
    "    # If still None, populate 'N/A' to match your requested shape\n",
    "    salary_min = salary_min if salary_min is not None else 'N/A'\n",
    "    salary_max = salary_max if salary_max is not None else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'company_name': company_name,\n",
    "        'job_title': job_title,\n",
    "        'job_description': job_description,\n",
    "        'salary_min': salary_min,\n",
    "        'salary_max': salary_max,\n",
    "    }\n",
    "\n",
    "def scrape_all_jobs(max_pages=None, pause=0.5):\n",
    "    session, csrf = get_session_and_csrf()\n",
    "    all_jobs = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        soup = get_list_page(session, csrf, page=page)\n",
    "        chunk = parse_list_items(soup)\n",
    "        if not chunk:\n",
    "            break\n",
    "        all_jobs.extend(chunk)\n",
    "        page += 1\n",
    "        if max_pages and page > max_pages:\n",
    "            break\n",
    "        time.sleep(pause)\n",
    "    return session, csrf, all_jobs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    session, csrf, job_listings = scrape_all_jobs()\n",
    "    print(f\"Found {len(job_listings)} listings\")\n",
    "\n",
    "    job_info_list = []\n",
    "    for j in job_listings:\n",
    "        job_url = j.get(\"url\")\n",
    "        if not job_url:\n",
    "            continue\n",
    "        info = extract_job_info(session, csrf, job_url)\n",
    "        try:\n",
    "            print(info[\"job_title\"], info[\"company_name\"], info[\"job_description\"] )\n",
    "            job_info_list.append(info)\n",
    "        except Exception:\n",
    "            print(f\"Could not extract info from: {job_url}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n✅ Extracted {len(job_info_list)} job details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95d844e1-0dd5-4314-bca6-f5cb743ab08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ ...</td>\n",
       "      <td>Software Development Engineer 2-6</td>\n",
       "      <td>None</td>\n",
       "      <td>158000</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ ...</td>\n",
       "      <td>Junior Automation Tester</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ ...</td>\n",
       "      <td>Staff Facilities Engineer (Electrical)</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ ...</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ ...</td>\n",
       "      <td>IT Infrastructure Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name                               job_title job_description  \\\n",
       "0        @ ...       Software Development Engineer 2-6            None   \n",
       "1        @ ...                Junior Automation Tester            None   \n",
       "2        @ ...  Staff Facilities Engineer (Electrical)            None   \n",
       "3        @ ...                Senior Software Engineer            None   \n",
       "4        @ ...              IT Infrastructure Engineer            None   \n",
       "\n",
       "  salary_min salary_max  \n",
       "0     158000     210000  \n",
       "1        N/A        N/A  \n",
       "2        N/A        N/A  \n",
       "3        N/A        N/A  \n",
       "4        N/A        N/A  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(job_info_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7347271-5d1d-4628-ab26-5eb32da8c9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 listings\n",
      "Software Development Engineer 2-6 @ ... N/A\n",
      "Junior Automation Tester @ ... N/A\n",
      "Staff Facilities Engineer (Electrical) @ ... N/A\n",
      "Senior Software Engineer @ ... N/A\n",
      "Software System Engineer @ ... N/A\n",
      "Java Fullstack Developer - 2-4 Years @ ... N/A\n",
      "IT Infrastructure Engineer @ ... N/A\n",
      "Senior Technical Support Engineer (Integration) @ ... N/A\n",
      "Teamcenter Systems Administrator (Onsite) @ ... N/A\n",
      "Database Engineer- Sr. Consultant level- NoSQL @ ... N/A\n",
      "Software Engineer OOP (Hybrid) @ ... N/A\n",
      "Senior Solution Engineer, Insurance @ ... N/A\n",
      "Service Now Developer @ ... N/A\n",
      "Cloud Infrastructure Engineer - Hybrid Tempe @ ... N/A\n",
      "Cybersecurity Engineer, M&A Automation @ ... N/A\n",
      "Senior Data Scientist @ ... N/A\n",
      "Staff Software Engineer @ ... N/A\n",
      "Software Engineer @ ... N/A\n",
      "Consultant- Data Analyst @ ... N/A\n",
      "Senior Data Engineer II @ ... N/A\n",
      "Senior Software Engineer II , Retail Pricing @ ... N/A\n",
      "Senior Software Engineer II, Commercial & Wealth @ ... N/A\n",
      "Staff Full-Stack Software Engineer, Dev Agent Tools @ ... N/A\n",
      "Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience @ ... N/A\n",
      "Staff Software Engineer, Lending @ ... N/A\n",
      "Staff Software Engineer, Tokenization @ ... N/A\n",
      "Senior Staff Test Engineer / Team Leader @ ... N/A\n",
      "AI Research Engineer- Advanced Driving Assistance Systems (ADAS) @ ... N/A\n",
      "Associate Solutions Designer @ ... N/A\n",
      "Principal Engineer Software (Prisma Access) - NetSec @ ... N/A\n",
      "Backend Engineer @ ... N/A\n",
      "Staff Engineer Software (Prisma Access)- NetSec @ ... N/A\n",
      "Solutions Consultant 2 - FSI @ ... N/A\n",
      "Cybersecurity Engineer - GRC @ ... N/A\n",
      "Senior Staff Software Engineer (Cloud NW & AI Security) @ ... N/A\n",
      "Desarrollador Backend Java Semisenior @ ... N/A\n",
      "Technical Enablement Specialist - NetSec @ ... N/A\n",
      "Senior Identity Security Services Engineer @ ... N/A\n",
      "Data Insights Engineer @ ... N/A\n",
      "Industrial Engineer @ ... N/A\n",
      "Creative Graphic Engineer - AI & Design @ ... N/A\n",
      "Conversational AI Developer (Google CCAI / AWS) @ ... N/A\n",
      "Senior Software Engineer @ ... N/A\n",
      "Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance @ ... N/A\n",
      "Engineer, Software Development Engineering (Apps) @ ... N/A\n",
      "MID Software Engineer / Fullstack @ ... N/A\n",
      "Data Governance Specialist @ ... N/A\n",
      "Data Governance Specialist @ ... N/A\n",
      "Sr Dir PM, Data & Analytics @ ... N/A\n",
      "Senior Data Engineer I @ ... N/A\n",
      "Senior Technical Marketing Engineer (SASE) @ ... N/A\n",
      "Sr Software Engineer Backend @ ... N/A\n",
      "C++ Software Engineer - Trading applications @ ... N/A\n",
      "Senior C++ Developer @ ... N/A\n",
      "Staff Software Engineer @ ... N/A\n",
      "Scientific Data Analyst @ ... N/A\n",
      "Sr Production Service Engineer - Cloud Operations - Federal @ ... N/A\n",
      "Network Systems Engineer (Pre-Sales) @ ... N/A\n",
      "Senior Solutions Engineer, PAM @ ... N/A\n",
      "Principal Software Engineer (Intrusion Prevention System Development) @ ... N/A\n",
      "Senior Engineering Manager – Data Science (Pricing & Fleet Optimization) (m/f/d) @ ... N/A\n",
      "Ops Test Analyst - China Lake CA @ ... N/A\n",
      "Senior Data Engineer @ ... N/A\n",
      "Backup and Recovery Administrator @ ... N/A\n",
      "Senior Genesys Cloud CX Consultant @ ... N/A\n",
      "Product Marketing Manager @ ... N/A\n",
      "Associate Software Engineer @ ... N/A\n",
      "Associate Flood Modeller / Hydrologist @ ... N/A\n",
      "Senior Manager, Retail Analytics @ ... N/A\n",
      "Cyber Threat Analyst 1 @ ... N/A\n",
      "Développeur Fullstack PHP Symfony / React senior H/F @ ... N/A\n",
      "Engineer II, Golang - (Logistics, Deliveries) @ ... N/A\n",
      "Senior BI Engineer @ ... N/A\n",
      "Software Engineer-Python | DevOps | Cloud @ ... N/A\n",
      "Director, Data Science, Visa Consulting & Analytics, India and South Asia @ ... N/A\n",
      "Staff Product Security Engineer @ ... N/A\n",
      "Senior Data Engineer (Pipelines & Ingestion) (f/m/d) - Metrify Smart Metering @ ... N/A\n",
      "Algorithm Engineer @ ... N/A\n",
      "Senior Data Engineer @ ... N/A\n",
      "Software Engineer IV @ ... N/A\n",
      "Software Engineer III @ ... N/A\n",
      "AI Engineer @ ... N/A\n",
      "Alternance – Data analyst F/H @ ... N/A\n",
      "Associate AI Engineer @ ... N/A\n",
      "Enterprise Account Executive, IL @ ... N/A\n",
      "Chef de projet MOE H/F @ ... N/A\n",
      "Website Content Manager @ ... N/A\n",
      "Backend Engineer Golang  (f|m|d) (100%) - Sophia-Antipolis - Hybrid or Remote working model @ ... N/A\n",
      "Web Designer @ ... N/A\n",
      "IT Infrastructure Director @ ... N/A\n",
      "Site Reliability Developer 4 @ ... N/A\n",
      "Technical Product Manager @ ... N/A\n",
      "Senior Data Scientist @ ... N/A\n",
      "Mitarbeiter:in Data Science & Customer Support Freiburg im Breisgau oder Aachen, Deutschland @ ... N/A\n",
      "Product Owner DATA @ ... N/A\n",
      "Software Engineer with PHP, Symfony Framework  & DB experience @ ... N/A\n",
      "Site Reliability Engineer @ ... N/A\n",
      "Senior Software Architect @ ... N/A\n",
      "Data & Reporting System(s) Coordinator @ ... N/A\n",
      "Data & Reporting System(s) Coordinator @ ... N/A\n",
      "\n",
      "✅ Extracted 100 job details.\n"
     ]
    }
   ],
   "source": [
    "import re, json, html\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def _clean_html_text(s, keep_newlines=False):\n",
    "    \"\"\"Collapse HTML to readable text.\"\"\"\n",
    "    if s is None:\n",
    "        return None\n",
    "    # unescape & strip\n",
    "    t = BeautifulSoup(s, \"html.parser\").get_text(\"\\n\" if keep_newlines else \" \", strip=True)\n",
    "    # squash whitespace\n",
    "    t = re.sub(r\"[ \\t\\r\\f\\v]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip() or None\n",
    "\n",
    "def _extract_from_json_ld(soup):\n",
    "    \"\"\"\n",
    "    Return (company_name, job_title, job_description, salary_min, salary_max)\n",
    "    from JobPosting JSON-LD if present; otherwise all Nones.\n",
    "    \"\"\"\n",
    "    for script in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "        raw = script.string or \"\"\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "        except Exception:\n",
    "            continue\n",
    "        nodes = data if isinstance(data, list) else [data]\n",
    "        for obj in nodes:\n",
    "            if not isinstance(obj, dict):\n",
    "                continue\n",
    "            t = obj.get(\"@type\")\n",
    "            if t == \"JobPosting\" or (isinstance(t, list) and \"JobPosting\" in t):\n",
    "                # company / title / description\n",
    "                company = None\n",
    "                org = obj.get(\"hiringOrganization\")\n",
    "                if isinstance(org, dict):\n",
    "                    company = org.get(\"name\") or org.get(\"legalName\")\n",
    "                title = obj.get(\"title\")\n",
    "                desc = obj.get(\"description\")\n",
    "                desc = _clean_html_text(desc, keep_newlines=True)\n",
    "\n",
    "                # salary\n",
    "                salary_min = salary_max = None\n",
    "                base = obj.get(\"baseSalary\") or {}\n",
    "                if isinstance(base, dict):\n",
    "                    val = base.get(\"value\")\n",
    "                    if isinstance(val, dict):\n",
    "                        salary_min = val.get(\"minValue\")\n",
    "                        salary_max = val.get(\"maxValue\")\n",
    "\n",
    "                return company, title, desc, salary_min, salary_max\n",
    "    return None, None, None, None, None\n",
    "\n",
    "def _visible_salary_min_max(soup):\n",
    "    badge = soup.select_one(\".text-success-emphasis, .salary, .badge.text-success-emphasis\")\n",
    "    txt = badge.get_text(\" \", strip=True) if badge else None\n",
    "    if not txt:\n",
    "        return None, None\n",
    "    nums = []\n",
    "    for num, suf in re.findall(r'(\\d+(?:[\\d,]*)(?:\\.\\d+)?)([KkMm]?)', txt):\n",
    "        n = float(num.replace(\",\", \"\"))\n",
    "        if suf.lower() == 'k':\n",
    "            n *= 1_000\n",
    "        elif suf.lower() == 'm':\n",
    "            n *= 1_000_000\n",
    "        nums.append(int(n))\n",
    "    if len(nums) >= 2:\n",
    "        return nums[0], nums[1]\n",
    "    return None, None\n",
    "\n",
    "def _fallback_company(soup):\n",
    "    # Prefer company directory links; ignore bare '@' icons\n",
    "    cand = soup.select_one('a[href*=\"/hiring/companies/\"], .company a, .text-body-secondary a')\n",
    "    if cand:\n",
    "        txt = cand.get_text(strip=True)\n",
    "        if txt and txt != \"@\":\n",
    "            return txt\n",
    "    # Try og:site_name (last resort)\n",
    "    meta = soup.find(\"meta\", attrs={\"property\": \"og:site_name\"})\n",
    "    if meta and meta.get(\"content\"):\n",
    "        return meta[\"content\"].strip()\n",
    "    return None\n",
    "\n",
    "def _fallback_title(soup):\n",
    "    h = soup.select_one(\"h1, h2, h3, .job-title, .card-title, .h3\")\n",
    "    return h.get_text(strip=True) if h else None\n",
    "\n",
    "def _fallback_description(soup):\n",
    "    el = soup.select_one(\".job-description, article, .content, .prose, .markdown, .card-body\")\n",
    "    if el:\n",
    "        return _clean_html_text(str(el), keep_newlines=True)\n",
    "    # fallback to meta description\n",
    "    meta = soup.find(\"meta\", attrs={\"name\": \"description\"}) or soup.find(\"meta\", attrs={\"property\": \"og:description\"})\n",
    "    if meta and meta.get(\"content\"):\n",
    "        return meta[\"content\"].strip()\n",
    "    return None\n",
    "\n",
    "def extract_job_info(session, csrf, job_url):\n",
    "    \"\"\"\n",
    "    Fetch the HTMX detail fragment (target mc_2) and extract:\n",
    "      company_name, job_title, job_description, salary_min, salary_max\n",
    "    \"\"\"\n",
    "    hdrs = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": \"https://foorilla.com/hiring/\",\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": \"mc_2\",\n",
    "        \"HX-Current-URL\": \"https://foorilla.com/hiring/\",\n",
    "        \"X-Screen\": \"D\",\n",
    "    }\n",
    "    if csrf:\n",
    "        hdrs[\"X-CSRFToken\"] = csrf\n",
    "\n",
    "    r = session.get(job_url, headers=hdrs, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # 1) Prefer JSON-LD (most reliable)\n",
    "    comp_json, title_json, desc_json, smin_json, smax_json = _extract_from_json_ld(soup)\n",
    "\n",
    "    # 2) Fallbacks for each field\n",
    "    company_name   = comp_json or _fallback_company(soup)\n",
    "    job_title      = title_json or _fallback_title(soup)\n",
    "    job_description= desc_json or _fallback_description(soup)\n",
    "\n",
    "    salary_min, salary_max = smin_json, smax_json\n",
    "    if salary_min is None and salary_max is None:\n",
    "        salary_min, salary_max = _visible_salary_min_max(soup)\n",
    "\n",
    "    # Normalize to your requested shape\n",
    "    return {\n",
    "        'company_name': company_name or 'N/A',\n",
    "        'job_title': job_title or 'N/A',\n",
    "        'job_description': job_description or 'N/A',\n",
    "        'salary_min': salary_min if salary_min is not None else 'N/A',\n",
    "        'salary_max': salary_max if salary_max is not None else 'N/A',\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    session, csrf, job_listings = scrape_all_jobs()\n",
    "    print(f\"Found {len(job_listings)} listings\")\n",
    "\n",
    "    job_info_list = []\n",
    "    for j in job_listings:\n",
    "        job_url = j.get(\"url\")\n",
    "        if not job_url:\n",
    "            continue\n",
    "        info = extract_job_info(session, csrf, job_url)\n",
    "        try:\n",
    "            print(info[\"job_title\"], info[\"company_name\"], info[\"job_description\"] )\n",
    "            job_info_list.append(info)\n",
    "        except Exception:\n",
    "            print(f\"Could not extract info from: {job_url}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n✅ Extracted {len(job_info_list)} job details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbc87d4a-473d-4bdb-81b1-5e48a096f0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'company_name': '@ ...', 'job_title': 'Software Development Engineer 2-6', 'job_description': 'N/A', 'salary_min': 158000, 'salary_max': 210000}\n",
      "2 {'company_name': '@ ...', 'job_title': 'Staff Facilities Engineer (Electrical)', 'job_description': 'N/A', 'salary_min': 'N/A', 'salary_max': 'N/A'}\n",
      "3 {'company_name': '@ ...', 'job_title': 'Senior Software Engineer', 'job_description': 'N/A', 'salary_min': 'N/A', 'salary_max': 'N/A'}\n",
      "Software Development Engineer 2-6\n",
      "Staff Facilities Engineer (Electrical)\n",
      "Senior Software Engineer\n",
      "Java Fullstack Developer - 2-4 Years\n",
      "Junior Automation Tester\n",
      "IT Infrastructure Engineer\n",
      "Software System Engineer\n",
      "Senior Technical Support Engineer (Integration)\n",
      "Teamcenter Systems Administrator (Onsite)\n",
      "Database Engineer- Sr. Consultant level- NoSQL\n",
      "Software Engineer OOP (Hybrid)\n",
      "Senior Solution Engineer, Insurance\n",
      "Service Now Developer\n",
      "Cloud Infrastructure Engineer - Hybrid Tempe\n",
      "Cybersecurity Engineer, M&A Automation\n",
      "Senior Data Scientist\n",
      "Staff Software Engineer\n",
      "Software Engineer\n",
      "Consultant- Data Analyst\n",
      "Senior Data Engineer II\n",
      "Senior Software Engineer II , Retail Pricing\n",
      "Senior Software Engineer II, Commercial & Wealth\n",
      "Staff Full-Stack Software Engineer, Dev Agent Tools\n",
      "Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience\n",
      "Staff Software Engineer, Lending\n",
      "Staff Software Engineer, Tokenization\n",
      "Senior Staff Test Engineer / Team Leader\n",
      "AI Research Engineer- Advanced Driving Assistance Systems (ADAS)\n",
      "Associate Solutions Designer\n",
      "Principal Engineer Software (Prisma Access) - NetSec\n",
      "Backend Engineer\n",
      "Staff Engineer Software (Prisma Access)- NetSec\n",
      "Solutions Consultant 2 - FSI\n",
      "Cybersecurity Engineer - GRC\n",
      "Senior Staff Software Engineer (Cloud NW & AI Security)\n",
      "Desarrollador Backend Java Semisenior\n",
      "Technical Enablement Specialist - NetSec\n",
      "Senior Identity Security Services Engineer\n",
      "Data Insights Engineer\n",
      "Industrial Engineer\n",
      "Creative Graphic Engineer - AI & Design\n",
      "Conversational AI Developer (Google CCAI / AWS)\n",
      "Senior Software Engineer\n",
      "Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance\n",
      "Engineer, Software Development Engineering (Apps)\n",
      "MID Software Engineer / Fullstack\n",
      "Data Governance Specialist\n",
      "Data Governance Specialist\n",
      "Sr Dir PM, Data & Analytics\n",
      "Senior Data Engineer I\n",
      "\n",
      "✅ Extracted 50 job details.\n"
     ]
    }
   ],
   "source": [
    "import re, json, time, os\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE  = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "LIST  = f\"{BASE}/hiring/jobs/\"\n",
    "UA = (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "      \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\")\n",
    "\n",
    "def session_and_csrf():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": UA})\n",
    "    r = s.get(START, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    m = re.search(r'\"X-CSRFToken\"\\s*:\\s*\"([^\"]+)\"', r.text)\n",
    "    csrf = m.group(1) if m else None\n",
    "    return s, csrf\n",
    "\n",
    "def htmx_headers(csrf=None, target=\"mc_1\"):\n",
    "    h = {\n",
    "        \"User-Agent\": UA,\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": START,\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": target,\n",
    "        \"HX-Current-URL\": START,\n",
    "        \"X-Screen\": \"D\",\n",
    "        # some servers key off this too\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    }\n",
    "    if csrf: h[\"X-CSRFToken\"] = csrf\n",
    "    return h\n",
    "\n",
    "def list_page(s, csrf, page=1):\n",
    "    url = LIST if page == 1 else f\"{LIST}?page={page}\"\n",
    "    r = s.get(url, headers=htmx_headers(csrf, \"mc_1\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_list(soup):\n",
    "    out = []\n",
    "    for row in soup.select(\"li.list-group-item\"):\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a: continue\n",
    "        hx = a.get(\"hx-get\")\n",
    "        if not hx: continue\n",
    "        out.append(urljoin(BASE, hx))\n",
    "    return out\n",
    "\n",
    "def clean_text(s, keep_n=False):\n",
    "    if not s: return None\n",
    "    t = BeautifulSoup(s, \"html.parser\").get_text(\"\\n\" if keep_n else \" \", strip=True)\n",
    "    t = re.sub(r\"[ \\t\\r\\f\\v]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip() or None\n",
    "\n",
    "def from_json_ld(soup):\n",
    "    for tag in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "        try:\n",
    "            data = json.loads(tag.string or \"\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        nodes = data if isinstance(data, list) else [data]\n",
    "        for obj in nodes:\n",
    "            if not isinstance(obj, dict): continue\n",
    "            t = obj.get(\"@type\")\n",
    "            if t == \"JobPosting\" or (isinstance(t, list) and \"JobPosting\" in t):\n",
    "                org = obj.get(\"hiringOrganization\") or {}\n",
    "                company = org.get(\"name\") or org.get(\"legalName\")\n",
    "                title = obj.get(\"title\")\n",
    "                desc  = clean_text(obj.get(\"description\"), keep_n=True)\n",
    "                base  = obj.get(\"baseSalary\") or {}\n",
    "                val   = base.get(\"value\") if isinstance(base, dict) else {}\n",
    "                smin  = (val or {}).get(\"minValue\")\n",
    "                smax  = (val or {}).get(\"maxValue\")\n",
    "                return company, title, desc, smin, smax\n",
    "    return None, None, None, None, None\n",
    "\n",
    "def visible_salary_minmax(soup):\n",
    "    badge = soup.select_one(\".text-success-emphasis, .salary, .badge.text-success-emphasis\")\n",
    "    txt = badge.get_text(\" \", strip=True) if badge else None\n",
    "    if not txt: return None, None\n",
    "    nums = []\n",
    "    for num, suf in re.findall(r'(\\d+(?:[\\d,]*)(?:\\.\\d+)?)([KkMm]?)', txt):\n",
    "        n = float(num.replace(\",\", \"\"))\n",
    "        if suf.lower() == \"k\": n *= 1_000\n",
    "        elif suf.lower() == \"m\": n *= 1_000_000\n",
    "        nums.append(int(n))\n",
    "    if len(nums) >= 2: return nums[0], nums[1]\n",
    "    return None, None\n",
    "\n",
    "def fallback_company(soup):\n",
    "    cand = soup.select_one('a[href*=\"/hiring/companies/\"], .company a, .text-body-secondary a')\n",
    "    if cand:\n",
    "        txt = cand.get_text(strip=True)\n",
    "        if txt and txt != \"@\":\n",
    "            return txt\n",
    "    meta = soup.find(\"meta\", attrs={\"property\": \"og:site_name\"})\n",
    "    return meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\n",
    "\n",
    "def fallback_title(soup):\n",
    "    h = soup.select_one(\"h1, h2, h3, .job-title, .card-title, .h3\")\n",
    "    if h: \n",
    "        t = h.get_text(strip=True)\n",
    "        if t: return t\n",
    "    meta = soup.find(\"meta\", attrs={\"property\": \"og:title\"})\n",
    "    return meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\n",
    "\n",
    "def fallback_desc(soup):\n",
    "    el = soup.select_one(\".job-description, article, .content, .prose, .markdown, .card-body\")\n",
    "    if el:\n",
    "        return clean_text(str(el), keep_n=True)\n",
    "    meta = soup.find(\"meta\", attrs={\"name\": \"description\"}) or soup.find(\"meta\", attrs={\"property\": \"og:description\"})\n",
    "    return meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\n",
    "\n",
    "def fetch_detail_fragment(s, csrf, url, debug_slug=None):\n",
    "    r = s.get(url, headers=htmx_headers(csrf, \"mc_2\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    html = r.text\n",
    "    if debug_slug:\n",
    "        with open(f\"debug_detail_{debug_slug}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "    return BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "def extract_job_info(s, csrf, job_url, debug_slug=None):\n",
    "    soup = fetch_detail_fragment(s, csrf, job_url, debug_slug=debug_slug)\n",
    "\n",
    "    # 1) JSON-LD first\n",
    "    c_json, t_json, d_json, smin_json, smax_json = from_json_ld(soup)\n",
    "\n",
    "    # 2) Fallbacks\n",
    "    company = c_json or fallback_company(soup) or \"N/A\"\n",
    "    title   = t_json or fallback_title(soup) or \"N/A\"\n",
    "    desc    = d_json or fallback_desc(soup) or \"N/A\"\n",
    "\n",
    "    smin, smax = smin_json, smax_json\n",
    "    if smin is None and smax is None:\n",
    "        smin, smax = visible_salary_minmax(soup)\n",
    "\n",
    "    return {\n",
    "        \"company_name\": company,\n",
    "        \"job_title\": title,\n",
    "        \"job_description\": desc,\n",
    "        \"salary_min\": smin if smin is not None else \"N/A\",\n",
    "        \"salary_max\": smax if smax is not None else \"N/A\",\n",
    "    }\n",
    "\n",
    "# ---- run a small end-to-end to verify and produce debug files ----\n",
    "if __name__ == \"__main__\":\n",
    "    s, csrf = session_and_csrf()\n",
    "    soup = list_page(s, csrf, page=1)\n",
    "    job_urls = parse_list(soup)\n",
    "    if not job_urls:\n",
    "        print(\"No job URLs found on page 1.\")\n",
    "        raise SystemExit(1)\n",
    "\n",
    "    # save first 3 detail fragments for inspection\n",
    "    for idx, ju in enumerate(job_urls[:3], 1):\n",
    "        info = extract_job_info(s, csrf, ju, debug_slug=f\"{idx}\")\n",
    "        print(idx, info)\n",
    "\n",
    "    # your requested loop\n",
    "    job_info_list = []\n",
    "    for ju in job_urls:\n",
    "        info = extract_job_info(s, csrf, ju)\n",
    "        try:\n",
    "            print(info[\"job_title\"])\n",
    "            job_info_list.append(info)\n",
    "        except Exception:\n",
    "            print(f\"Could not extract info from: {ju}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n✅ Extracted {len(job_info_list)} job details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b044c18e-f589-4f87-a75b-104c18d6e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listings collected: 100\n",
      "Software Development Engineer 2-6 | N/A | 158000 - 210000\n",
      "Staff Facilities Engineer (Electrical) | N/A | N/A - N/A\n",
      "Senior Software Engineer | N/A | N/A - N/A\n",
      "Java Fullstack Developer - 2-4 Years | N/A | N/A - N/A\n",
      "IT Infrastructure Engineer | N/A | N/A - N/A\n",
      "Software System Engineer | N/A | N/A - N/A\n",
      "Junior Automation Tester | N/A | N/A - N/A\n",
      "Senior Technical Support Engineer (Integration) | N/A | N/A - N/A\n",
      "Teamcenter Systems Administrator (Onsite) | N/A | 105000 - 125000\n",
      "Database Engineer- Sr. Consultant level- NoSQL | N/A | 135000 - 196000\n",
      "Software Engineer OOP (Hybrid) | N/A | 73000 - 85000\n",
      "Senior Solution Engineer, Insurance | N/A | 269000 - 364000\n",
      "Service Now Developer | N/A | N/A - N/A\n",
      "Cloud Infrastructure Engineer - Hybrid Tempe | N/A | 126000 - 200000\n",
      "Cybersecurity Engineer, M&A Automation | N/A | 116000 - 164000\n",
      "Senior Data Scientist | N/A | 117000 - 165000\n",
      "Staff Software Engineer | N/A | 149000 - 204000\n",
      "Software Engineer | N/A | 85000 - 110000\n",
      "Consultant- Data Analyst | N/A | 88000 - 108000\n",
      "Senior Data Engineer II | N/A | 130000 - 160000\n",
      "Senior Software Engineer II , Retail Pricing | N/A | 130000 - 160000\n",
      "Senior Software Engineer II, Commercial & Wealth | N/A | 130000 - 160000\n",
      "Staff Full-Stack Software Engineer, Dev Agent Tools | N/A | 163000 - 286000\n",
      "Business Analyst II (Data & Compliance Analyst II) - Legacy, IS Operational Experience | N/A | 85000 - 135000\n",
      "Staff Software Engineer, Lending | N/A | 110000 - 162000\n",
      "Staff Software Engineer, Tokenization | N/A | 110000 - 162000\n",
      "Senior Staff Test Engineer / Team Leader | N/A | 137000 - 220000\n",
      "AI Research Engineer- Advanced Driving Assistance Systems (ADAS) | N/A | 165000 - 200000\n",
      "Associate Solutions Designer | N/A | 79000 - 113000\n",
      "Principal Engineer Software (Prisma Access) - NetSec | N/A | N/A - N/A\n",
      "Backend Engineer | N/A | N/A - N/A\n",
      "Staff Engineer Software (Prisma Access)- NetSec | N/A | N/A - N/A\n",
      "Solutions Consultant 2 - FSI | N/A | 198000 - 313000\n",
      "Cybersecurity Engineer - GRC | N/A | 116000 - 164000\n",
      "Senior Staff Software Engineer (Cloud NW & AI Security) | N/A | 126000 - 204000\n",
      "Desarrollador Backend Java Semisenior | N/A | N/A - N/A\n",
      "Technical Enablement Specialist - NetSec | N/A | 134000 - 215000\n",
      "Senior Identity Security Services Engineer | N/A | 90000 - 132000\n",
      "Data Insights Engineer | N/A | 124000 - 180000\n",
      "Industrial Engineer | N/A | 325000 - 405000\n",
      "Creative Graphic Engineer - AI & Design | N/A | N/A - N/A\n",
      "Conversational AI Developer (Google CCAI / AWS) | N/A | N/A - N/A\n",
      "Senior Software Engineer | N/A | N/A - N/A\n",
      "Cyber Security Engineer - Sr. Consultant level - Regulatory, Audit, & Compliance | N/A | 174000 - 253000\n",
      "Engineer, Software Development Engineering (Apps) | N/A | N/A - N/A\n",
      "MID Software Engineer / Fullstack | N/A | 24000 - 48000\n",
      "Data Governance Specialist | N/A | N/A - N/A\n",
      "Data Governance Specialist | N/A | N/A - N/A\n",
      "Sr Dir PM, Data & Analytics | N/A | 250000 - 437000\n",
      "Senior Data Engineer I | N/A | 110000 - 130000\n",
      "Senior Technical Marketing Engineer (SASE) | N/A | 134000 - 215000\n",
      "Sr Software Engineer Backend | N/A | N/A - N/A\n",
      "C++ Software Engineer - Trading applications | N/A | 175000 - 250000\n",
      "Senior C++ Developer | N/A | N/A - N/A\n",
      "Staff Software Engineer | N/A | 62000 - 93000\n",
      "Scientific Data Analyst | N/A | 89000 - 111000\n",
      "Sr Production Service Engineer - Cloud Operations - Federal | N/A | 126000 - 215000\n",
      "Network Systems Engineer (Pre-Sales) | N/A | 140000 - 192000\n",
      "Senior Solutions Engineer, PAM | N/A | 119000 - 175000\n",
      "Principal Software Engineer (Intrusion Prevention System Development) | N/A | 129000 - 194000\n",
      "Senior Engineering Manager – Data Science (Pricing & Fleet Optimization) (m/f/d) | N/A | N/A - N/A\n",
      "Ops Test Analyst - China Lake CA | Adp | 83000 - 132000\n",
      "Senior Data Engineer | N/A | 80000 - 100000\n",
      "Backup and Recovery Administrator | Adp | 85000 - 90000\n",
      "Senior Genesys Cloud CX Consultant | N/A | N/A - N/A\n",
      "Product Marketing Manager | Adp | N/A - N/A\n",
      "Associate Software Engineer | Adp | N/A - N/A\n",
      "Associate Flood Modeller / Hydrologist | Livehire | 123000 - 123000\n",
      "Senior Manager, Retail Analytics | Adp | 100000 - 125000\n",
      "Cyber Threat Analyst 1 | Adp | 107000 - 120000\n",
      "Développeur Fullstack PHP Symfony / React senior H/F | N/A | N/A - N/A\n",
      "Engineer II, Golang - (Logistics, Deliveries) | N/A | N/A - N/A\n",
      "Senior BI Engineer | Factorialhr | 50000 - 53000\n",
      "Software Engineer-Python | DevOps | Cloud | N/A | N/A - N/A\n",
      "Director, Data Science, Visa Consulting & Analytics, India and South Asia | N/A | N/A - N/A\n",
      "Staff Product Security Engineer | N/A | N/A - N/A\n",
      "Senior Data Engineer (Pipelines & Ingestion) (f/m/d) - Metrify Smart Metering | N/A | N/A - N/A\n",
      "Algorithm Engineer | Fetcherr | N/A - N/A\n",
      "Senior Data Engineer | N/A | N/A - N/A\n",
      "Software Engineer IV | Catsone | N/A - N/A\n",
      "Software Engineer III | Catsone | N/A - N/A\n",
      "AI Engineer | Doorloop | N/A - N/A\n",
      "Alternance – Data analyst F/H | Malakoffhumanis | N/A - N/A\n",
      "Associate AI Engineer | Doorloop | N/A - N/A\n",
      "Enterprise Account Executive, IL | Comeet | N/A - N/A\n",
      "Chef de projet MOE H/F | Gouv | N/A - N/A\n",
      "Website Content Manager | Comeet | 54000 - 59000\n",
      "Backend Engineer Golang  (f|m|d) (100%) - Sophia-Antipolis - Hybrid or Remote working model | N/A | 198000 - 236000\n",
      "Web Designer | Atera | N/A - N/A\n",
      "IT Infrastructure Director | Solaredge | N/A - N/A\n",
      "Site Reliability Developer 4 | Oraclecloud | N/A - N/A\n",
      "Technical Product Manager | Overwolf | N/A - N/A\n",
      "Senior Data Scientist | N/A | N/A - N/A\n",
      "Mitarbeiter:in Data Science & Customer Support Freiburg im Breisgau oder Aachen, Deutschland | Join | 50000 - 80000\n",
      "Product Owner DATA | N/A | N/A - N/A\n",
      "Software Engineer with PHP, Symfony Framework  & DB experience | N/A | N/A - N/A\n",
      "Site Reliability Engineer | Paymentology | 38000 - 76000\n",
      "Senior Software Architect | Comeet | N/A - N/A\n",
      "Data & Reporting System(s) Coordinator | Adp | 62000 - 68000\n",
      "Data & Reporting System(s) Coordinator | Adp | 62000 - 68000\n",
      "\n",
      "✅ Extracted 100 jobs.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE  = \"https://foorilla.com\"\n",
    "START = f\"{BASE}/hiring/\"\n",
    "LIST  = f\"{BASE}/hiring/jobs/\"\n",
    "UA = (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "      \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def session_and_csrf():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": UA})\n",
    "    r = s.get(START, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    m = re.search(r'\"X-CSRFToken\"\\s*:\\s*\"([^\"]+)\"', r.text)\n",
    "    csrf = m.group(1) if m else None\n",
    "    return s, csrf\n",
    "\n",
    "def htmx_headers(csrf=None, target=\"mc_1\"):\n",
    "    h = {\n",
    "        \"User-Agent\": UA,\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Referer\": START,\n",
    "        \"HX-Request\": \"true\",\n",
    "        \"HX-Target\": target,\n",
    "        \"HX-Current-URL\": START,\n",
    "        \"X-Screen\": \"D\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    }\n",
    "    if csrf: h[\"X-CSRFToken\"] = csrf\n",
    "    return h\n",
    "\n",
    "def list_page(s, csrf, page=1):\n",
    "    url = LIST if page == 1 else f\"{LIST}?page={page}\"\n",
    "    r = s.get(url, headers=htmx_headers(csrf, \"mc_1\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def parse_list_items(soup):\n",
    "    \"\"\"Return list of dicts: {url, listing_salary, listing_location, listing_title}\"\"\"\n",
    "    out = []\n",
    "    for row in soup.select(\"li.list-group-item\"):\n",
    "        a = row.select_one(\"a.stretched-link\")\n",
    "        if not a: \n",
    "            continue\n",
    "        hx_get = a.get(\"hx-get\")\n",
    "        if not hx_get:\n",
    "            continue\n",
    "        url = urljoin(BASE, hx_get)\n",
    "        title = a.get_text(strip=True)\n",
    "\n",
    "        # badge salary text like \"USD 135K-180K\"\n",
    "        sal_el = row.select_one(\".text-success-emphasis\")\n",
    "        listing_salary = sal_el.get_text(\" \", strip=True) if sal_el else None\n",
    "\n",
    "        loc_el = row.select_one(\".hstack .text-end small\")\n",
    "        location = loc_el.get_text(strip=True) if loc_el else None\n",
    "\n",
    "        out.append({\n",
    "            \"url\": url,\n",
    "            \"listing_title\": title,\n",
    "            \"listing_salary\": listing_salary,\n",
    "            \"listing_location\": location\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def fetch_detail_fragment_html(s, csrf, detail_url):\n",
    "    r = s.get(detail_url, headers=htmx_headers(csrf, \"mc_2\"), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r.text  # <-- THIS is fragment_html\n",
    "\n",
    "def parse_salary_range_text(text):\n",
    "    if not text:\n",
    "        return None, None\n",
    "    nums = []\n",
    "    for num, suf in re.findall(r'(\\d+(?:[\\d,]*)(?:\\.\\d+)?)([KkMm]?)', text):\n",
    "        n = float(num.replace(\",\", \"\"))\n",
    "        if suf.lower() == 'k': n *= 1_000\n",
    "        elif suf.lower() == 'm': n *= 1_000_000\n",
    "        nums.append(int(n))\n",
    "    if len(nums) >= 2:\n",
    "        return nums[0], nums[1]\n",
    "    return None, None\n",
    "\n",
    "def infer_company_from_domain(url):\n",
    "    try:\n",
    "        host = urlparse(url).netloc.lower()\n",
    "        host = re.sub(r'^(jobs?|careers?|boards?|app|apply)\\.', '', host)\n",
    "        ats_hosts = ('greenhouse.io','lever.co','workday.com','myworkdayjobs.com',\n",
    "                     'smartrecruiters.com','ashbyhq.com','bamboohr.com','jobvite.com',\n",
    "                     'icims.com','eightfold.ai','recruitee.com')\n",
    "        if any(h in host for h in ats_hosts):\n",
    "            return None\n",
    "        parts = host.split('.')\n",
    "        core = parts[-2] if len(parts) >= 2 else parts[0]\n",
    "        core = re.sub(r'[^a-z0-9]+', ' ', core).strip()\n",
    "        return core.title() if core else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------- extraction from fragment ----------\n",
    "def extract_job_info_from_fragment(fragment_html, listing_salary_text=None):\n",
    "    soup = BeautifulSoup(fragment_html, \"html.parser\")\n",
    "\n",
    "    # Title\n",
    "    h = soup.select_one(\"h1, h2, h3, .job-title, .card-title, .h3\")\n",
    "    job_title = h.get_text(strip=True) if h else None\n",
    "\n",
    "    # Company often anonymized as '@ ...'\n",
    "    company_link = soup.select_one(\".hstack strong a, .text-body-secondary a, .company a\")\n",
    "    company_text = (company_link.get_text(strip=True) if company_link else None)\n",
    "    company_name = None if (not company_text or company_text.startswith('@')) else company_text\n",
    "\n",
    "    # Build description from visible sections\n",
    "    parts = []\n",
    "    def get_section(label_regex, next_selector=\"ul\"):\n",
    "        label = soup.find(string=re.compile(label_regex, re.I))\n",
    "        if label:\n",
    "            parent = label.find_parent()\n",
    "            if parent:\n",
    "                nxt = parent.find_next(next_selector)\n",
    "                if nxt:\n",
    "                    if next_selector == \"ul\":\n",
    "                        items = [li.get_text(\" \", strip=True) for li in nxt.find_all(\"li\")]\n",
    "                        return \"; \".join(items) if items else nxt.get_text(\" \", strip=True)\n",
    "                    else:\n",
    "                        return nxt.get_text(\" \", strip=True)\n",
    "        return None\n",
    "\n",
    "    tasks = get_section(r\"^\\s*Tasks:\\s*$\", \"ul\")\n",
    "    if tasks and tasks != \"N/A\":\n",
    "        parts.append(\"Tasks: \" + tasks)\n",
    "\n",
    "    skills = get_section(r\"Skills/Tech-stack required:\", \"div\")\n",
    "    if skills and skills != \"N/A\":\n",
    "        parts.append(\"Skills: \" + skills)\n",
    "\n",
    "    perks = get_section(r\"Perks/Benefits:\", \"ul\")\n",
    "    if perks and perks != \"N/A\":\n",
    "        parts.append(\"Perks: \" + perks)\n",
    "\n",
    "    job_description = \"\\n\".join(parts) if parts else None\n",
    "\n",
    "    # Salary min/max from listing badge (preferred), else from fragment badge\n",
    "    salary_text = listing_salary_text\n",
    "    if not salary_text:\n",
    "        badge = soup.select_one(\".text-success-emphasis, .salary, .badge.text-success-emphasis\")\n",
    "        salary_text = badge.get_text(\" \", strip=True) if badge else None\n",
    "    salary_min, salary_max = parse_salary_range_text(salary_text)\n",
    "\n",
    "    # Apply link (for potential company inference)\n",
    "    apply_el = soup.select_one('a.btn.btn-primary[href*=\"/apply/\"]')\n",
    "    apply_link = urljoin(BASE, apply_el[\"href\"]) if apply_el and apply_el.has_attr(\"href\") else None\n",
    "\n",
    "    return {\n",
    "        'company_name': company_name,  # may be None if anonymized\n",
    "        'job_title': job_title,\n",
    "        'job_description': job_description,\n",
    "        'salary_min': salary_min if salary_min is not None else 'N/A',\n",
    "        'salary_max': salary_max if salary_max is not None else 'N/A',\n",
    "        'apply_link': apply_link\n",
    "    }\n",
    "\n",
    "def resolve_apply_destination(session, apply_url):\n",
    "    try:\n",
    "        r = session.head(apply_url, headers={\"User-Agent\": UA, \"Referer\": START}, allow_redirects=True, timeout=20)\n",
    "        return r.url\n",
    "    except Exception:\n",
    "        try:\n",
    "            r = session.get(apply_url, headers={\"User-Agent\": UA, \"Referer\": START}, allow_redirects=True, timeout=20)\n",
    "            return r.url\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "# ---------- main ----------\n",
    "if __name__ == \"__main__\":\n",
    "    s, csrf = session_and_csrf()\n",
    "\n",
    "    # get first N pages (remove max_pages to crawl all)\n",
    "    all_listings = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        soup = list_page(s, csrf, page=page)\n",
    "        chunk = parse_list_items(soup)\n",
    "        if not chunk:\n",
    "            break\n",
    "        all_listings.extend(chunk)\n",
    "        page += 1\n",
    "        # optional: limit pages while testing\n",
    "        if page > 3:\n",
    "            break\n",
    "        time.sleep(0.4)\n",
    "\n",
    "    print(f\"Listings collected: {len(all_listings)}\")\n",
    "\n",
    "    job_info_list = []\n",
    "    for j in all_listings:\n",
    "        job_url = j[\"url\"]\n",
    "        # === THIS populates fragment_html ===\n",
    "        fragment_html = fetch_detail_fragment_html(s, csrf, job_url)\n",
    "\n",
    "        info = extract_job_info_from_fragment(\n",
    "            fragment_html,\n",
    "            listing_salary_text=j.get(\"listing_salary\")\n",
    "        )\n",
    "\n",
    "        # If company hidden, try to infer via Apply redirect\n",
    "        if not info['company_name'] and info.get('apply_link'):\n",
    "            dest = resolve_apply_destination(s, info['apply_link'])\n",
    "            inferred = infer_company_from_domain(dest) if dest else None\n",
    "            if inferred:\n",
    "                info['company_name'] = inferred\n",
    "\n",
    "        # Print and store\n",
    "        print(info['job_title'], \"|\", info['company_name'] or \"N/A\",\n",
    "              \"|\", info['salary_min'], \"-\", info['salary_max'])\n",
    "        job_info_list.append({\n",
    "            'company_name': info['company_name'] or 'N/A',\n",
    "            'job_title': info['job_title'] or 'N/A',\n",
    "            'job_description': info['job_description'] or 'N/A',\n",
    "            'salary_min': info['salary_min'],\n",
    "            'salary_max': info['salary_max']\n",
    "        })\n",
    "\n",
    "    print(f\"\\n✅ Extracted {len(job_info_list)} jobs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaa0fa34-3887-471e-9af1-9fd570c187f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>Software Development Engineer 2-6</td>\n",
       "      <td>Tasks: * Build and maintain scalable microserv...</td>\n",
       "      <td>158000</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>Staff Facilities Engineer (Electrical)</td>\n",
       "      <td>Tasks: * Conduct load analysis and risk assess...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Tasks: * Adapt to changing project priorities;...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>Java Fullstack Developer - 2-4 Years</td>\n",
       "      <td>Tasks: * Assess risks and ensure compliance; *...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>IT Infrastructure Engineer</td>\n",
       "      <td>Tasks: * Apply patches and updates; * Build an...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name                               job_title  \\\n",
       "0          N/A       Software Development Engineer 2-6   \n",
       "1          N/A  Staff Facilities Engineer (Electrical)   \n",
       "2          N/A                Senior Software Engineer   \n",
       "3          N/A    Java Fullstack Developer - 2-4 Years   \n",
       "4          N/A              IT Infrastructure Engineer   \n",
       "\n",
       "                                     job_description salary_min salary_max  \n",
       "0  Tasks: * Build and maintain scalable microserv...     158000     210000  \n",
       "1  Tasks: * Conduct load analysis and risk assess...        N/A        N/A  \n",
       "2  Tasks: * Adapt to changing project priorities;...        N/A        N/A  \n",
       "3  Tasks: * Assess risks and ensure compliance; *...        N/A        N/A  \n",
       "4  Tasks: * Apply patches and updates; * Build an...        N/A        N/A  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(job_info_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "700ab31e-5783-43ae-bf02-f8c072915b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/ai_job_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33d71512-70ec-4f2f-b184-bd1d1ed2c26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Adp</td>\n",
       "      <td>Ops Test Analyst - China Lake CA</td>\n",
       "      <td>Tasks: * Analyze pre-test predictions and data...</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>132000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Adp</td>\n",
       "      <td>Backup and Recovery Administrator</td>\n",
       "      <td>Tasks: * Administer backup and recovery operat...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Livehire</td>\n",
       "      <td>Associate Flood Modeller / Hydrologist</td>\n",
       "      <td>Tasks: * Conduct flood impact and waterway ass...</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>123000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Adp</td>\n",
       "      <td>Senior Manager, Retail Analytics</td>\n",
       "      <td>Tasks: * Collaborate with marketing, finance, ...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Adp</td>\n",
       "      <td>Cyber Threat Analyst 1</td>\n",
       "      <td>Tasks: * Analyze security events in SIEM envir...</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_name                               job_title  \\\n",
       "61          Adp        Ops Test Analyst - China Lake CA   \n",
       "63          Adp       Backup and Recovery Administrator   \n",
       "67     Livehire  Associate Flood Modeller / Hydrologist   \n",
       "68          Adp        Senior Manager, Retail Analytics   \n",
       "69          Adp                  Cyber Threat Analyst 1   \n",
       "\n",
       "                                      job_description  salary_min  salary_max  \n",
       "61  Tasks: * Analyze pre-test predictions and data...     83000.0    132000.0  \n",
       "63  Tasks: * Administer backup and recovery operat...     85000.0     90000.0  \n",
       "67  Tasks: * Conduct flood impact and waterway ass...    123000.0    123000.0  \n",
       "68  Tasks: * Collaborate with marketing, finance, ...    100000.0    125000.0  \n",
       "69  Tasks: * Analyze security events in SIEM envir...    107000.0    120000.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ai_job_data.csv\")\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31105e-e4c5-41de-baf4-38cf49c35b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e25cedeb-5117-4292-9221-80c6cac8e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_job_title(title):\n",
    "    \"\"\"\n",
    "    Standardizes a given job title string by returning a predefined canonical job title without adding seniority levels.\n",
    "\n",
    "    Args:\n",
    "        title (str): The job title string to be standardized.\n",
    "\n",
    "    Returns:\n",
    "        str: A standardized job title based on predefined categories, handling compound roles\n",
    "             and specialized AI-related job functions.\n",
    "    \"\"\"\n",
    "    title = title.lower()\n",
    "    \n",
    "    # Define keyword mappings for specialized roles\n",
    "    role_mappings = {\n",
    "        \"AI Scientist\": [\"ai scientist\", \"ml scientist\", \"ai/ml scientist\"],\n",
    "        \"Prompt Engineer\": [\"prompt engineer\"],\n",
    "        \"Deep Learning Engineer\": [\"deep learning\", \"dl engineer\", \"deep learning systems\"],\n",
    "        \"Data Scientist\": [\"data scientist\", \"decision scientist\", \"analytics scientist\"],\n",
    "        \"Decision Science Analyst\": [\"decision science\", \"decision analyst\"],\n",
    "        \"Software Engineer\": [\"software engineer\", \"full stack\", \"backend\", \"frontend\", \"performance engineer\"],\n",
    "        \"Data Engineer\": [\"data engineer\", \"etl developer\", \"pipeline engineer\", \"spark\", \"scala\", \"aws\"],\n",
    "        \"ML Ops Engineer\": [\"ml ops\", \"model development\", \"ml operations\", \"applied data science\"],\n",
    "        \"Security Engineer\": [\"security engineer\", \"data security\"],\n",
    "        \"Electrical Engineer\": [\"electrical design\", \"data center design\"],\n",
    "        \"Manager\": [\"manager\", \"product manager\", \"project manager\"],\n",
    "        \"Director\": [\"director\", \"head of\", \"vp\", \"vice president\"],\n",
    "        \"Intern\": [\"intern\", \"trainee\"],\n",
    "        \"Researcher\": [\"researcher\", \"research engineer\"],\n",
    "    }\n",
    "\n",
    "    # Check for keywords in the title and return the corresponding standardized title\n",
    "    for standard_title, keywords in role_mappings.items():\n",
    "        if any(keyword in title for keyword in keywords):\n",
    "            return standard_title\n",
    "    \n",
    "    # Return \"Other\" if no match is found\n",
    "    return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56131ca-cbe3-4460-87aa-744f1faeb050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad77db59-2c98-4a65-b4f7-7400c1f80f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num raw job titles: 10\n",
      "Num standardized job titles: 2\n"
     ]
    }
   ],
   "source": [
    "# Apply the regex-based function to the job_title column\n",
    "df['standardized_job_title'] = df['job_title'].apply(standardize_job_title)\n",
    "\n",
    "print(\"Num raw job titles:\", df['job_title'].nunique())\n",
    "print(\"Num standardized job titles:\", df['standardized_job_title'].nunique())\n",
    "\n",
    "# sum max salary for each standardized job title\n",
    "s_jobs = df.groupby('standardized_job_title')['salary_max'].mean()\n",
    "s_jobs = s_jobs.sort_values()\n",
    "\n",
    "# convert to dataframe\n",
    "df_jobs = s_jobs.reset_index()\n",
    "df_jobs.columns = [\"Job Title\", \"Mean Salary\"]\n",
    "df_jobs.head()\n",
    "\n",
    "\n",
    "def extract_skills(description):\n",
    "    \"\"\"\n",
    "    Extracts AI-related skills from a given job description.\n",
    "\n",
    "    Args:\n",
    "        description (str): The job description text to search for skills.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of skills found in the job description, matched from a predefined set of common AI-related skills.\n",
    "\n",
    "    Notes:\n",
    "        - The function defines a list of common AI-related skills, including programming languages, frameworks,\n",
    "          cloud platforms, and statistical concepts.\n",
    "        - The input description is converted to lowercase to ensure case-insensitive matching.\n",
    "        - Skills are detected using regular expressions to match whole words, avoiding partial matches (e.g., \n",
    "          \"spark\" will not match \"sparking\").\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a list of common AI-related skills\n",
    "    skills_list = [\n",
    "        \"python\", \"r\", \"java\", \"c++\", \"sql\", \"scala\", \"spark\", \"hadoop\", \"tensorflow\", \"pytorch\",\n",
    "        \"keras\", \"scikit-learn\", \"machine learning\", \"deep learning\", \"nlp\", \"natural language processing\",\n",
    "        \"computer vision\", \"data analysis\", \"data engineering\", \"big data\", \"ai\", \"artificial intelligence\",\n",
    "        \"cloud\", \"aws\", \"azure\", \"gcp\", \"docker\", \"kubernetes\", \"linux\", \"flask\", \"django\", \"pandas\",\n",
    "        \"numpy\", \"matplotlib\", \"seaborn\", \"plotly\", \"etl\", \"api\", \"statistics\", \"probability\", \"regression\",\n",
    "        \"classification\", \"clustering\", \"time series\", \"neural networks\", \"bayesian methods\", \"git\", \"mlops\"\n",
    "    ]\n",
    "\n",
    "    description = description.lower()\n",
    "    found_skills = [skill for skill in skills_list if re.search(rf\"\\b{re.escape(skill)}\\b\", description)]\n",
    "    \n",
    "    return found_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4dd95-8719-4e82-afc1-8656800347c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a61b69d-8bf2-4fec-8af4-cd9be54fc061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>etl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kubernetes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Skill  Count\n",
       "2           r      1\n",
       "7         etl      1\n",
       "6         aws      1\n",
       "4          ai      1\n",
       "9  kubernetes      1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to extract skills from each job description\n",
    "df['extracted_skills'] = df['job_description'].apply(lambda x: extract_skills(str(x)))\n",
    "df['extracted_skills'].head()\n",
    "\n",
    "# create a list with all the skills from the JDs\n",
    "all_skills = [skill for skills in df['extracted_skills'] for skill in skills]\n",
    "\n",
    "# count skill occurances\n",
    "skill_counts = Counter(all_skills)\n",
    "\n",
    "# Convert the skill counts to a DataFrame\n",
    "df_skills = pd.DataFrame(skill_counts.items(), columns=[\"Skill\", \"Count\"]).sort_values(by=\"Count\")\n",
    "df_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ff087e3-d06e-4209-a7ba-99a0d7fa1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import plotly.express as px\n",
    "from dash import dcc, html, Dash\n",
    "\n",
    "# Create the plots\n",
    "bar_chart = dcc.Graph(\n",
    "    id='top-roles',\n",
    "    figure=px.bar(df.sort_values(by='salary_max', ascending=False), \n",
    "                  x='standardized_job_title', \n",
    "                  y='salary_max', \n",
    "                  color='company_name', \n",
    "                  title='Highest Paying AI Jobs',\n",
    "                  labels={'salary_max': 'Maximum Salary', 'job_title': 'Job Title'},\n",
    "                  height=500)\n",
    ")\n",
    "\n",
    "top_jobs_chart = dcc.Graph(\n",
    "    id='top-jobs-chart',\n",
    "    figure=px.bar(\n",
    "        df_jobs[-5:],\n",
    "        y='Job Title',      \n",
    "        x='Mean Salary',\n",
    "        title='Top 5 Roles',\n",
    "        height=250\n",
    "    ).update_layout(\n",
    "        xaxis_title_font_size=12,    # Reduce x-axis label font size\n",
    "        yaxis_title_font_size=12,    # Reduce y-axis label font size\n",
    "        xaxis_tickfont_size=10,      # Reduce x-axis tick label font size\n",
    "        yaxis_tickfont_size=10       # Reduce y-axis tick label font size\n",
    "    )\n",
    ")\n",
    "\n",
    "top_skills_chart = dcc.Graph(\n",
    "    id='top-skills-chart',\n",
    "    figure=px.bar(\n",
    "        df_skills[-5:],\n",
    "        y='Skill',      \n",
    "        x='Count',\n",
    "        title='Top 5 Skills',\n",
    "        height=250\n",
    "    ).update_layout(\n",
    "        xaxis_title_font_size=12,    # Reduce x-axis label font size\n",
    "        yaxis_title_font_size=12,    # Reduce y-axis label font size\n",
    "        xaxis_tickfont_size=10,      # Reduce x-axis tick label font size\n",
    "        yaxis_tickfont_size=10       # Reduce y-axis tick label font size\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba0c87b6-79d5-4eb0-ae40-2d82570f1c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:9000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7e00051f6cf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout with styled divs for positioning\n",
    "app.layout = html.Div([\n",
    "    html.Div(bar_chart, style={'width': '70%', 'display': 'inline-block', 'vertical-align': 'top'}),\n",
    "    html.Div([\n",
    "        html.Div(top_jobs_chart, style={'height': '50%'}),\n",
    "        html.Div(top_skills_chart, style={'height': '50%'})\n",
    "    ], style={'width': '30%', 'display': 'inline-block', 'vertical-align': 'top'})\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "#app.run(jupyter_mode=\"external\")\n",
    "\n",
    "app.run(host=\"0.0.0.0\", port=9000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b170f2-04b7-4823-af1d-4b7edbce46ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
